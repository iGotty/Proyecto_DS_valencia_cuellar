# Plan de Entrega Final - Proyecto DS
**Fecha l√≠mite:** Noviembre 30, 2025
**Equipo:** Juan David Valencia, Juan Esteban Cuellar
**Curso:** MINE-4101 - Ciencia de Datos Aplicada

---

## üìä Estado General del Proyecto

| Componente | Estado | Progreso | √öltima actualizaci√≥n |
|------------|--------|----------|---------------------|
| Documentaci√≥n mejorada | ‚úÖ Completado | 100% | 2025-11-23 |
| Preparaci√≥n de datos | ‚úÖ Completado | 100% | 2025-11-23 |
| Estrategia de validaci√≥n | ‚è≥ Pendiente | 0% | - |
| Construcci√≥n de modelos | ‚è≥ Pendiente | 0% | - |
| Dashboard & producto | ‚è≥ Pendiente | 0% | - |
| Feedback stakeholders | ‚è≥ Pendiente | 0% | - |
| Conclusiones finales | ‚è≥ Pendiente | 0% | - |
| Video presentaci√≥n | ‚è≥ Pendiente | 0% | - |

**Leyenda:** ‚è≥ Pendiente | üîÑ En Proceso | ‚úÖ Completado | ‚ö†Ô∏è Bloqueado

**Progreso General:** 37.5% (2 de 8 fases completadas)

---

## üéØ Objetivos de la Entrega Final

1. **[20%]** Preparaci√≥n de datos para modelado
2. **[5%]** Estrategia de validaci√≥n y selecci√≥n de modelo
3. **[20%]** Construcci√≥n y evaluaci√≥n de modelos (m√≠nimo 3 algoritmos)
4. **[20%]** Construcci√≥n del producto de datos funcional
5. **[15%]** Retroalimentaci√≥n de stakeholders (m√≠nimo 3 interacciones)
6. **[15%]** Conclusiones y resumen ejecutivo
7. **[10%]** Autoevaluaci√≥n y evaluaci√≥n grupal

---

## üìù Comentarios del Profesor a Atender

### Definici√≥n de Problem√°tica (8.5/10)
- [ ] **KPIs m√°s claros:** Definir expl√≠citamente recencia, CPOI (Costo Por Orden Incremental)
- [ ] **Impacto medible:** Declarar impacto esperado en m√©tricas (ej: "aumentar usuarios activos de 29.7% a 35%")
- [ ] **Generalizaci√≥n:** Eliminar rangos de fechas espec√≠ficos, hacer el enfoque generalizable
- [ ] **M√°s detalle en KPIs:** Explicar qu√© significa cada m√©trica en contexto de negocio

### Ideaci√≥n (7.5/10)
- [ ] **Alineaci√≥n mockup:** Mostrar claramente d√≥nde est√°n las predicciones en el dashboard
- [ ] **Conexiones clave:** Explicar por qu√© predecir probabilidad de reorden a 30-90 d√≠as
- [ ] **Afinidades:** Detallar c√≥mo se analizan afinidades de cada segmento (son din√°micas, de datos hist√≥ricos)
- [ ] **Customer journey:** Agregar diagrama de customer journey

### Enfoque Anal√≠tico (10.875/15) - **CR√çTICO**
- [ ] **Tipo de modelo claro:** Especificar clasificaci√≥n vs regresi√≥n
- [ ] **Variable objetivo:** Definir expl√≠citamente (delta_orders para regresi√≥n, high_growth para clasificaci√≥n)
- [ ] **Proceso de factores:** Explicar c√≥mo se identificar√°n factores de crecimiento
- [ ] **M√∫ltiples modelos:** Clarificar si hay 1 o varios modelos para las 3 hip√≥tesis
- [ ] **M√©tricas de evaluaci√≥n:** Detallar m√©tricas espec√≠ficas (AUC, RMSE, etc.)
- [ ] **T√©cnicas de agrupaci√≥n:** Especificar t√©cnica (K-Means) y m√©tricas (Silhouette)
- [ ] **Literatura acad√©mica:** Agregar referencias que avalen el enfoque

### Entendimiento de Datos (29.75/35)
- [ ] **P-values:** Mostrar p-values de todas las correlaciones reportadas
- [ ] **Grupos ANOVA:** Especificar qu√© grupos se compararon (5 categor√≠as de recencia)
- [ ] **Effect sizes:** Reportar tama√±o de efecto (Œ∑¬≤), no solo p-value
- [ ] **Categor√≠as:** Listar expl√≠citamente las 6 categor√≠as principales de afinidad
- [ ] **Detalles video:** Incluir en documento: # usuarios, √≥rdenes por usuario, promedios, ventanas de tiempo

### Recolecci√≥n de Datos (9/10)
- [ ] **Detalles faltantes:** Agregar: 41,667 usuarios, avg 7.2 √≥rdenes/usuario, ventana 6 meses

---

## üóìÔ∏è FASE 1: Mejorar Documentaci√≥n (D√≠a 1)

**Estado:** ‚è≥ Pendiente
**Objetivo:** Atender todos los comentarios del profesor en secciones existentes

### Tareas

#### 1.1 Secci√≥n de Problem√°tica
- [ ] Reescribir definici√≥n de KPIs con formato:
  ```
  **Recencia:** D√≠as desde √∫ltima orden. Categor√≠as: Activo (‚â§7d), Semi-Activo (8-14d),
  Tibio (15-30d), Fr√≠o (31-90d), Perdido (>90d)

  **CPOI (Costo Por Orden Incremental):** Presupuesto promocional / delta_orders

  **Tasa de retenci√≥n:** % usuarios que realizan al menos 1 orden post-4ta orden

  **Impacto esperado:**
  - Usuarios activos: +18% (29.7% ‚Üí 35%)
  - Delta promedio: +16% (6.9 ‚Üí 8.0 √≥rdenes)
  - CPOI: -15%
  ```
- [ ] Eliminar fechas espec√≠ficas (mar-sep 2025), reemplazar con "cohorte de usuarios que alcanzaron 4ta orden"
- [ ] Agregar tabla de m√©tricas baseline vs objetivo

#### 1.2 Secci√≥n de Ideaci√≥n
- [ ] Crear diagrama de customer journey (simple, con touchpoints principales)
- [ ] Agregar mockup mejorado del dashboard con anotaciones que muestren:
  - D√≥nde aparece probabilidad de reorden 30-90d
  - C√≥mo se visualizan las afinidades por segmento
  - Conexi√≥n predicci√≥n ‚Üí acci√≥n recomendada
- [ ] Explicar por qu√© 30-90 d√≠as: "Ventana de planificaci√≥n presupuestaria del equipo de Engagement"
- [ ] Aclarar que afinidades son din√°micas: calculadas de `main_category_counts` por usuario

#### 1.3 Secci√≥n de Enfoque Anal√≠tico - **REFORZAR**
- [ ] Crear tabla de modelos:
  ```markdown
  | Modelo | Tipo | Variable Objetivo | Algoritmos | M√©tricas Evaluaci√≥n |
  |--------|------|-------------------|------------|---------------------|
  | Modelo 1 | Clasificaci√≥n | high_growth (delta>8) | RF, XGBoost, LightGBM | AUC-ROC, F1, Precision@20% |
  | Modelo 2 | Regresi√≥n | delta_orders (continua) | RF Reg, XGBoost Reg, Ridge | RMSE, MAE, R¬≤ |
  | Segmentaci√≥n | Clustering | Features m√∫ltiples | K-Means | Silhouette, Davies-Bouldin |
  ```
- [ ] Explicar relaci√≥n modelos-hip√≥tesis:
  - Hip√≥tesis 1 (velocidad ‚Üí crecimiento): Ambos modelos usan efo_to_four como feature
  - Hip√≥tesis 2 (recencia ‚Üí volumen): Ambos modelos usan categoria_recencia como feature
  - Hip√≥tesis 3 (afinidades ‚Üí personalizaci√≥n): Clustering + features de afinidad en modelos
- [ ] Agregar 2-3 referencias acad√©micas:
  - Churn prediction (Verbeke et al.)
  - E-commerce behavior (papers de Kaggle/arXiv)
  - Retention modeling

#### 1.4 Secci√≥n de Entendimiento de Datos
- [ ] Crear tabla de resultados estad√≠sticos completa:
  ```markdown
  | An√°lisis | Test | Resultado | P-value | Effect Size | Interpretaci√≥n |
  |----------|------|-----------|---------|-------------|----------------|
  | Velocidad-Crecimiento | Pearson | r = -0.201 | p < 0.001 | - | Correlaci√≥n negativa significativa |
  | Recencia-Crecimiento | ANOVA | F = 1087.5 | p < 0.001 | Œ∑¬≤ = 0.073 | Efecto mediano, muy significativo |
  | Grupos comparados | - | Activo, Semi-Activo, Tibio, Fr√≠o, Perdido | - | - | 5 categor√≠as de recencia |
  ```
- [ ] Listar las 6 categor√≠as principales: [extraer de affinity_analysis.py]
- [ ] Agregar secci√≥n "Resumen del Dataset":
  - 41,667 usuarios
  - 7.2 √≥rdenes promedio por usuario
  - 6.9 delta_orders promedio
  - Ventana observaci√≥n: 6 meses
  - 15 variables, 0% missing, 0% duplicados

#### 1.5 Archivo a Actualizar
- [ ] Crear/actualizar: `documento/ENTREGA_FINAL.md` (compilaci√≥n de todas las secciones)

**Archivos generados:**
- `documento/ENTREGA_FINAL.md` (versi√≥n mejorada con feedback incorporado)
- `documento/figuras/customer_journey.png` (diagrama nuevo)
- `documento/figuras/mockup_mejorado.png` (opcional, si hay tiempo)

---

## üîß FASE 2: Preparaci√≥n de Datos (D√≠a 2) - [20% de la nota]

**Estado:** ‚úÖ Completado
**Objetivo:** Feature engineering, encoding, splitting - todo documentado

### 2.1 Feature Engineering

#### Variables Num√©ricas Transformadas
- [x] `log_total_orders`: np.log1p(total_orders) - manejar asimetr√≠a
- [x] `log_efo_to_four`: np.log1p(efo_to_four)
- [x] `orders_per_day`: total_orders / d√≠as desde first_order_date

#### Variables Categ√≥ricas Derivadas
- [x] `is_weekend_first_order`: 1 si first_order_date fue s√°bado/domingo, 0 si no
- [x] `first_order_month`: mes de la primera orden (estacionalidad)
- [x] `days_since_first_order`: d√≠as desde primera orden (antig√ºedad)

#### Features de Afinidad (desde columnas dict)
- [x] `dominant_category`: categor√≠a con m√°s √≥rdenes (extraer de main_category_counts)
- [x] `category_diversity`: √çndice Shannon de main_category_counts
- [x] `num_categories`: len(main_category_counts.keys())
- [x] `num_shops`: len(shop_name_counts.keys())
- [x] `num_brands`: len(brand_name_counts.keys())
- [x] `brand001_ratio`: brand_counts['brand001'] / total_orders

#### Target Variables
- [x] `high_growth`: 1 si delta_orders > 8, else 0 (clasificaci√≥n)
- [x] `delta_orders`: as-is (regresi√≥n)

### 2.2 Encoding & Scaling
- [x] One-hot encoding: categoria_recencia, city_token, r_segment, dominant_category, is_weekend_first_order (40 features)
- [x] StandardScaler: variables num√©ricas (11 features) ‚Üí media‚âà0, std‚âà1
- [x] Guardar transformers: `feature_engineering_pipeline.pkl` (3.9 KB)

### 2.3 Manejo de Outliers
- [x] Decisi√≥n: **MANTENER** outliers (usuarios con >14 √≥rdenes son power users v√°lidos)
- [x] Documentado en notebook y pipeline diagram

### 2.4 Data Splitting
- [x] Stratified split por `high_growth` (20.36% usuarios high-growth)
- [x] Train: 60% (25,000 users) - 9.5 MB
- [x] Validation: 20% (8,333 users) - 3.2 MB
- [x] Test: 20% (8,334 users) - 3.2 MB
- [x] Guardar: `data/processed/train.csv`, `val.csv`, `test.csv`
- [x] Verificaci√≥n: Distribuciones preservadas (high_growth: 20.36% en todos los sets)

### 2.5 Diagrama de Pipeline
- [x] Crear diagrama de flujo completo con Mermaid
- [x] Documentar detalle de cada transformaci√≥n
- [x] Guardar: `documento/diagrams/data_preparation_pipeline.md` (con Mermaid + tablas detalladas)

**Notebook creado:**
- ‚úÖ `notebooks/01_data_preparation.ipynb` (con todo el c√≥digo y explicaciones)

**Archivos generados:**
- ‚úÖ `data/processed/train.csv` (25,000 √ó 54) - 9.5 MB
- ‚úÖ `data/processed/val.csv` (8,333 √ó 54) - 3.2 MB
- ‚úÖ `data/processed/test.csv` (8,334 √ó 54) - 3.2 MB
- ‚úÖ `models/feature_engineering_pipeline.pkl` - 3.9 KB
- ‚úÖ `scripts/run_data_preparation.py` - Script ejecutable standalone
- ‚úÖ `documento/diagrams/data_preparation_pipeline.md` - Diagrama Mermaid completo

---

## üé≤ FASE 3: Estrategia de Validaci√≥n (D√≠a 2) - [5% de la nota]

**Estado:** ‚è≥ Pendiente
**Objetivo:** Definir y documentar estrategia de experimentaci√≥n

### 3.1 Estrategia de Experimentaci√≥n
- [ ] Documentar en secci√≥n del documento:
  ```markdown
  **Estrategia:**
  1. Entrenar m√∫ltiples algoritmos (RF, XGBoost, LightGBM) en conjunto TRAIN
  2. Optimizar hiperpar√°metros usando 5-fold cross-validation en TRAIN
  3. Seleccionar mejor configuraci√≥n evaluando en conjunto VALIDATION
  4. Evaluaci√≥n final del mejor modelo en conjunto TEST (1 sola vez)
  5. M√©tricas primarias: AUC-ROC (clasificaci√≥n), RMSE (regresi√≥n)
  ```

### 3.2 Verificaci√≥n de Distribuciones
- [ ] Crear tabla comparativa:
  ```markdown
  | Variable | Train | Validation | Test | Chi¬≤ p-value |
  |----------|-------|------------|------|--------------|
  | growth_segment (Low) | 32.7% | 32.6% | 32.8% | 0.95 (OK) |
  | growth_segment (Medium) | 46.9% | 47.1% | 46.7% | 0.93 (OK) |
  | categoria_recencia (Activo) | 29.7% | 29.8% | 29.5% | 0.97 (OK) |
  | ... | ... | ... | ... | ... |
  ```
- [ ] Test Chi-cuadrado para confirmar que splits preservan distribuci√≥n original

### 3.3 Cross-Validation Setup
- [ ] StratifiedKFold con 5 folds
- [ ] Semilla aleatoria: 42 (reproducibilidad)
- [ ] Scoring: 'roc_auc' (clasificaci√≥n), 'neg_root_mean_squared_error' (regresi√≥n)

**Notebook a crear:**
- Secci√≥n en `notebooks/01_data_preparation.ipynb` O nuevo `notebooks/02_validation_strategy.ipynb`

**Archivos generados:**
- Tabla de distribuciones en documento
- Configuraci√≥n de CV documentada

---

## ü§ñ FASE 4: Construcci√≥n y Evaluaci√≥n de Modelos (D√≠as 3-4) - [20% de la nota]

**Estado:** ‚è≥ Pendiente
**Objetivo:** Entrenar m√≠nimo 3 algoritmos, evaluar, seleccionar mejor

### 4.1 Modelos de Clasificaci√≥n (Predecir high_growth)

#### Random Forest Classifier
- [ ] Grid de hiperpar√°metros:
  - n_estimators: [100, 200, 300]
  - max_depth: [10, 20, None]
  - min_samples_split: [2, 5, 10]
- [ ] GridSearchCV con 5-fold CV
- [ ] Entrenar en TRAIN, validar en VALIDATION
- [ ] Guardar: `models/rf_classifier.pkl`

#### XGBoost Classifier
- [ ] Grid de hiperpar√°metros:
  - n_estimators: [100, 200]
  - max_depth: [3, 5, 7]
  - learning_rate: [0.01, 0.1, 0.3]
  - subsample: [0.8, 1.0]
- [ ] GridSearchCV con 5-fold CV
- [ ] Guardar: `models/xgb_classifier.pkl`

#### LightGBM Classifier
- [ ] Grid de hiperpar√°metros:
  - n_estimators: [100, 200]
  - num_leaves: [31, 50]
  - learning_rate: [0.01, 0.1]
- [ ] GridSearchCV con 5-fold CV
- [ ] Guardar: `models/lgbm_classifier.pkl`

#### Evaluaci√≥n Clasificaci√≥n
- [ ] M√©tricas en VALIDATION:
  - AUC-ROC (objetivo: > 0.75)
  - F1-Score
  - Precision, Recall
  - Precision@20% (para targeting top 20%)
  - Matriz de confusi√≥n
- [ ] Crear tabla comparativa de resultados
- [ ] Seleccionar mejor modelo

### 4.2 Modelos de Regresi√≥n (Predecir delta_orders)

#### Random Forest Regressor
- [ ] Grid de hiperpar√°metros similares a clasificador
- [ ] Guardar: `models/rf_regressor.pkl`

#### XGBoost Regressor
- [ ] Grid de hiperpar√°metros similares a clasificador
- [ ] Guardar: `models/xgb_regressor.pkl`

#### Ridge Regression (Baseline)
- [ ] Alphas: [0.1, 1.0, 10.0, 100.0]
- [ ] Guardar: `models/ridge_regressor.pkl`

#### Evaluaci√≥n Regresi√≥n
- [ ] M√©tricas en VALIDATION:
  - RMSE (objetivo: < 3.5)
  - MAE
  - R¬≤
  - MAPE (Mean Absolute Percentage Error)
- [ ] Crear tabla comparativa de resultados
- [ ] Seleccionar mejor modelo

### 4.3 Evaluaci√≥n Cuantitativa
- [ ] Tabla de performance de todos los modelos:
  ```markdown
  | Modelo | AUC-ROC | F1 | Precision@20% | RMSE | MAE | R¬≤ | Tiempo entreno |
  |--------|---------|----|--------------|----|-----|----|----|
  | RF Classifier | 0.XX | 0.XX | 0.XX | - | - | - | XX min |
  | XGB Classifier | 0.XX | 0.XX | 0.XX | - | - | - | XX min |
  | ... | ... | ... | ... | ... | ... | ... | ... |
  ```
- [ ] Learning curves (train vs validation score)
- [ ] CV scores con desviaci√≥n est√°ndar

### 4.4 Evaluaci√≥n Cualitativa
- [ ] **Feature Importance:**
  - Extraer top 15 features m√°s importantes
  - Validar que recency y velocity est√©n en top 5 (coherente con EDA)
  - Visualizar gr√°fico de importancias
- [ ] **An√°lisis de Errores:**
  - ¬øD√≥nde falla el modelo? (ej: usuarios "Tibio" son dif√≠ciles de predecir)
  - ¬øHay patrones en los falsos positivos/negativos?
- [ ] **Interpretabilidad de Negocio:**
  - ¬øPueden los stakeholders confiar en las predicciones?
  - ¬øSon las features importantes accionables? (ej: recencia s√≠, user_id no)

### 4.5 Mejoras Identificadas (para documentar)
- [ ] Listar oportunidades de mejora:
  - Agregar features temporales (estacionalidad)
  - Datos externos (promociones recibidas)
  - Modelos ensemble (stacking)
  - Ajuste de threshold para clasificaci√≥n (seg√∫n costo/beneficio)

### 4.6 Selecci√≥n Final
- [ ] **Mejor clasificador:** [TBD - ej: XGBoost con AUC=0.XX]
- [ ] **Mejor regresor:** [TBD - ej: Random Forest con RMSE=X.XX]
- [ ] Guardar modelos finales:
  - `models/best_classifier.pkl`
  - `models/best_regressor.pkl`

**Notebooks a crear:**
- `notebooks/02_model_training_classification.ipynb`
- `notebooks/03_model_training_regression.ipynb`
- `notebooks/04_model_evaluation.ipynb`

**Archivos generados:**
- 6+ archivos .pkl de modelos
- Tablas de resultados
- Gr√°ficos de feature importance, learning curves, matriz confusi√≥n
- Secci√≥n completa de modelado en documento

---

## üíª FASE 5: Construcci√≥n del Producto de Datos (D√≠as 5-6) - [20% de la nota]

**Estado:** ‚è≥ Pendiente
**Objetivo:** Dashboard funcional con modelo integrado + sistema de recomendaci√≥n

### 5.1 Dashboard Streamlit - Estructura

#### P√°gina 1: Executive Dashboard
- [ ] **KPI Cards (4 m√©tricas principales):**
  - Avg delta_orders: [valor] (con cambio vs baseline)
  - % Usuarios activos: [valor]%
  - % High-growth users: [valor]%
  - Growth predicho (modelo): [valor]
- [ ] **Gr√°fico 1:** Serie de tiempo de nuevos usuarios por mes (from first_order_date)
- [ ] **Gr√°fico 2:** Distribuci√≥n de recencia (pie chart)
- [ ] **Gr√°fico 3:** Growth segment distribution (bar chart)

#### P√°gina 2: Segmentation Explorer
- [ ] **Filtros laterales:**
  - Recency category (multiselect)
  - R segment (multiselect)
  - City (multiselect)
  - Growth level (slider: Low/Medium/High/Very High)
- [ ] **Tabla din√°mica:** Usuarios filtrados (mostrar primeros 100)
- [ ] **Gr√°fico 1:** Scatter plot velocity vs growth (usuarios filtrados)
- [ ] **Gr√°fico 2:** Bar chart de performance por segmento

#### P√°gina 3: Model Predictions & Recommendations ‚≠ê
- [ ] **Input panel:**
  - Opci√≥n 1: Seleccionar usuario de test set (dropdown)
  - Opci√≥n 2: Ingresar features manualmente (form)
- [ ] **Prediction output:**
  - Probabilidad de high-growth: [0.XX] (con gauge visual)
  - Delta orders predicho: [X.X √≥rdenes]
  - Intervalo de confianza: [X.X - X.X]
- [ ] **Recommendation panel:**
  - Prioridad: Alta/Media/Baja (basada en probabilidad)
  - Top 3 categor√≠as recomendadas (de afinidades del usuario)
  - Acci√≥n sugerida (ej: "Enviar cup√≥n de Groceries, usuario tiene 85% prob de crecimiento")
- [ ] **Feature importance para este usuario:** SHAP values locales (opcional, nice-to-have)

#### P√°gina 4: Affinity Analysis
- [ ] **Gr√°fico 1:** Top 10 categor√≠as por segmento (grouped bar chart)
- [ ] **Gr√°fico 2:** Brand concentration (brand001 vs otros - pie chart)
- [ ] **Gr√°fico 3:** Avg # stores por growth segment
- [ ] **Tabla:** Top 20 tiendas (shop_name) por volumen de √≥rdenes

### 5.2 Sistema de Recomendaci√≥n - L√≥gica
- [ ] Implementar funci√≥n `recommend_users()`:
  ```python
  def recommend_users(user_features_df, model, top_pct=0.2, budget=100000):
      # 1. Predecir crecimiento para todos los usuarios
      predictions = model.predict_proba(user_features_df)[:, 1]

      # 2. Rankear usuarios por probabilidad de high-growth
      ranked = user_features_df.copy()
      ranked['growth_prob'] = predictions
      ranked = ranked.sort_values('growth_prob', ascending=False)

      # 3. Seleccionar top 20% como "Alta prioridad"
      n_top = int(len(ranked) * top_pct)
      high_priority = ranked.head(n_top)

      # 4. Asignar budget proporcionalmente
      high_priority['budget_allocated'] = budget * (high_priority['growth_prob'] / high_priority['growth_prob'].sum())

      # 5. Match con categor√≠as dominantes
      high_priority['recommended_category'] = high_priority['dominant_category']

      return high_priority[['user_id', 'growth_prob', 'recommended_category', 'budget_allocated']]
  ```

### 5.3 Integraci√≥n del Modelo
- [ ] Cargar modelos en app:
  ```python
  import pickle
  classifier = pickle.load(open('models/best_classifier.pkl', 'rb'))
  regressor = pickle.load(open('models/best_regressor.pkl', 'rb'))
  pipeline = pickle.load(open('models/feature_engineering_pipeline.pkl', 'rb'))
  ```
- [ ] Implementar preprocessing en tiempo real (aplicar pipeline a inputs)
- [ ] Cach√© de predicciones para test set (evitar recomputar)

### 5.4 Deployment
- [ ] **Local:**
  - Crear `dashboard/requirements.txt`:
    ```
    streamlit==1.28.0
    pandas==2.1.0
    numpy==1.25.0
    scikit-learn==1.3.0
    xgboost==2.0.0
    lightgbm==4.1.0
    plotly==5.17.0
    ```
  - Crear `dashboard/README.md` con instrucciones:
    ```bash
    pip install -r requirements.txt
    streamlit run app.py
    ```
- [ ] **Cloud (opcional - bonus):**
  - Deploy a Streamlit Cloud (gratis, shareable)
  - Configurar secrets para rutas de modelos

### 5.5 Diagrama de Arquitectura
- [ ] Crear diagrama con componentes:
  ```
  [Data Sources] ‚Üí [ETL Pipeline] ‚Üí [Feature Engineering] ‚Üí [Model Training] ‚Üí [Trained Models (.pkl)]
                                                                                    ‚Üì
  [User Input] ‚Üí [Streamlit App] ‚Üí [Preprocessing] ‚Üí [Model Inference] ‚Üí [Predictions] ‚Üí [Recommendations] ‚Üí [Dashboard UI]
  ```
- [ ] Herramienta: draw.io, Lucidchart, o Mermaid
- [ ] Guardar: `documento/figuras/arquitectura_producto.png`

**Archivos a crear:**
- `dashboard/app.py` (aplicaci√≥n Streamlit completa)
- `dashboard/requirements.txt`
- `dashboard/README.md`
- `dashboard/utils.py` (funciones helper para recomendaci√≥n)
- `documento/figuras/arquitectura_producto.png`

**Screenshots a capturar para documento:**
- Dashboard p√°gina 1 (KPIs)
- Dashboard p√°gina 3 (predicci√≥n + recomendaci√≥n)

---

## üë• FASE 6: Retroalimentaci√≥n de Stakeholders (D√≠as 4, 6) - [15% de la nota]

**Estado:** ‚è≥ Pendiente
**Objetivo:** Documentar m√≠nimo 3 interacciones (formato bit√°cora)

### Interacci√≥n #1: Primera Entrega (Ya realizada)
- [ ] Documentar en formato bit√°cora:
  ```markdown
  ### Interacci√≥n 1: Validaci√≥n de Enfoque Anal√≠tico
  **Fecha:** [Fecha de primera entrega]
  **Duraci√≥n:** Presentaci√≥n + feedback escrito
  **Participantes:**
  - Juan David Valencia (estudiante)
  - Juan Esteban Cuellar (estudiante)
  - Profesor MINE-4101
  - TAs del curso

  **Objetivo:** Presentar problem√°tica, datos recolectados, EDA inicial, hip√≥tesis validadas

  **Puntos Discutidos:**
  - Calidad de los datos (100/100)
  - Validaci√≥n de 3 hip√≥tesis con tests estad√≠sticos
  - Hallazgos clave: recencia 7x impacto, velocidad 2.3x impacto
  - Propuesta de soluci√≥n: dashboard + modelo + recomendador

  **Feedback Recibido:**
  - [Incluir comentarios del profesor del scoring anterior]
  - KPIs necesitan m√°s claridad y definici√≥n de impacto
  - Enfoque anal√≠tico debe especificar tipos de modelo y variables objetivo
  - Agregar p-values y effect sizes a reporte de EDA

  **Acuerdos:**
  - Reforzar secci√≥n de enfoque anal√≠tico con tabla de modelos
  - Incluir customer journey diagram
  - Agregar referencias acad√©micas

  **Pr√≥ximos Pasos:**
  - Incorporar feedback en documento final
  - Proceder con preparaci√≥n de datos y modelado
  ```

### Interacci√≥n #2: Validaci√≥n de Modelos (A realizar - D√≠a 4)
- [ ] **Preparar presentaci√≥n de resultados preliminares:**
  - Performance de 3+ algoritmos
  - Feature importance (top 10)
  - M√©tricas en validation set
- [ ] **Stakeholders:** Profesor y/o compa√±eros (peer review)
- [ ] **Preguntas a resolver:**
  - ¬øAUC > 0.75 es suficiente para el negocio?
  - ¬øLas features m√°s importantes son accionables?
  - ¬øQu√© threshold usar para clasificaci√≥n? (optimizar precision vs recall)
- [ ] **Documentar en bit√°cora:**
  - Fecha, participantes, duraci√≥n
  - Resultados presentados
  - Feedback recibido
  - Decisiones tomadas (ej: "usar threshold 0.6 para balance precision-recall")
  - Ajustes a implementar

### Interacci√≥n #3: Demo del Dashboard (A realizar - D√≠a 6)
- [ ] **Preparar demo en vivo del dashboard:**
  - Mostrar las 4 p√°ginas
  - Realizar predicci√≥n de ejemplo
  - Explicar sistema de recomendaci√≥n
- [ ] **Stakeholders:** Profesor y/o usuarios simulados (compa√±eros)
- [ ] **Preguntas a resolver:**
  - ¬øEs intuitivo el dashboard?
  - ¬øLas recomendaciones tienen sentido de negocio?
  - ¬øQu√© features adicionales ser√≠an √∫tiles?
- [ ] **Documentar en bit√°cora:**
  - Feedback de usabilidad
  - Sugerencias de mejora
  - Aprobaci√≥n del producto final
  - Pr√≥ximos pasos para productivizaci√≥n (fase 2 del proyecto)

**Formato de bit√°cora** (template para interacciones 2 y 3):
```markdown
### Interacci√≥n [N]: [T√≠tulo]
**Fecha:** YYYY-MM-DD
**Duraci√≥n:** XX minutos
**Participantes:**
- [Nombre] ([Rol])
- [Nombre] ([Rol])

**Objetivo:** [Qu√© se buscaba lograr en esta interacci√≥n]

**Puntos Discutidos:**
- [Punto 1]
- [Punto 2]
- [Punto 3]

**Feedback Recibido:**
- [Feedback 1]
- [Feedback 2]

**Decisiones Tomadas:**
- [Decisi√≥n 1]
- [Decisi√≥n 2]

**Acuerdos:**
- [Acuerdo 1]
- [Acuerdo 2]

**Pr√≥ximos Pasos:**
- [ ] [Acci√≥n 1] (Responsable: X)
- [ ] [Acci√≥n 2] (Responsable: Y)
```

**Archivo a crear:**
- `documento/BITACORA_STAKEHOLDERS.md` (con las 3 interacciones documentadas)

---

## üìÑ FASE 7: Conclusiones y Resumen Ejecutivo (D√≠a 7) - [15% de la nota]

**Estado:** ‚è≥ Pendiente
**Objetivo:** Responder 5 preguntas obligatorias + resumen ejecutivo

### 7.1 Respuestas a Preguntas Obligatorias

#### Pregunta 1: ¬øSe cumplieron los objetivos del proyecto?
- [ ] Escribir respuesta estructurada:
  ```markdown
  **S√≠, se cumplieron los objetivos principales:**

  ‚úÖ **Modelo predictivo:**
  - Clasificaci√≥n: AUC-ROC = [X.XX] (objetivo: >0.75)
  - Regresi√≥n: RMSE = [X.XX] √≥rdenes (objetivo: <3.5)
  - Identifica correctamente usuarios de alto crecimiento

  ‚úÖ **Dashboard interactivo:**
  - 4 p√°ginas funcionales (KPIs, segmentaci√≥n, predicciones, afinidades)
  - Integraci√≥n de modelos en tiempo real
  - Sistema de recomendaci√≥n implementado

  ‚úÖ **Validaci√≥n de hip√≥tesis:**
  - H1: Velocidad ‚Üí Crecimiento (validada, r=-0.201, p<0.001)
  - H2: Recencia ‚Üí Volumen (validada, 7x impacto, Œ∑¬≤=0.073)
  - H3: Afinidades ‚Üí Personalizaci√≥n (validada, 6 categor√≠as = 80% √≥rdenes)

  ‚ö†Ô∏è **Parcial:**
  - API REST no implementada (deprioritizada por tiempo, dashboard cubre 90% de casos de uso)
  ```

#### Pregunta 2: ¬øMayores dificultades durante el desarrollo?
- [ ] Listar dificultades y c√≥mo se resolvieron:
  ```markdown
  1. **Parsing de columnas diccionario:**
     - Problema: main_category_counts, brand_counts eran strings con formato dict
     - Soluci√≥n: ast.literal_eval() + manejo de errores

  2. **Alta dimensionalidad de afinidades:**
     - Problema: 817 marcas ‚Üí 817 features one-hot (curse of dimensionality)
     - Soluci√≥n: Feature selection (top-20 marcas) + feature engineering (√≠ndices de diversidad)

  3. **Desbalance de clases:**
     - Problema: 20.3% high-growth vs 32.7% low-growth
     - Soluci√≥n: Stratified sampling + m√©tricas apropiadas (AUC-ROC, no accuracy)

  4. **Tiempo limitado:**
     - Problema: 7 d√≠as para completar 8 secciones
     - Soluci√≥n: Priorizaci√≥n (dashboard Streamlit sobre API REST), trabajo en paralelo
  ```

#### Pregunta 3: ¬øImpacto estimado en KPIs al usar el producto?
- [ ] Calcular y justificar estimaciones:
  ```markdown
  **Baseline (sin producto):**
  - % Usuarios activos: 29.7%
  - Avg delta_orders: 6.9
  - CPOI (Cost Per Order Incremental): [valor base estimado]

  **Proyecci√≥n con producto (escenario conservador):**
  - % Usuarios activos: **+18%** ‚Üí 35%
    - Justificaci√≥n: Reactivaci√≥n de usuarios "Fr√≠o" (31-90d) con campa√±as dirigidas
  - Avg delta_orders: **+16%** ‚Üí 8.0 √≥rdenes
    - Justificaci√≥n: Foco de recursos en top 20% usuarios con mayor probabilidad
  - CPOI: **-15%** ‚Üí [valor reducido]
    - Justificaci√≥n: Menor desperdicio de presupuesto en usuarios de bajo potencial
  - Retenci√≥n usuarios "Tibio‚ÜíFr√≠o": **+20%**
    - Justificaci√≥n: Intervenci√≥n proactiva al detectar ca√≠da en recencia

  **Impacto estimado en ingresos:**
  - Incremento √≥rdenes = 41,667 usuarios √ó 1.1 √≥rdenes/usuario extra = 45,834 √≥rdenes adicionales
  - Valor promedio orden = [estimado] ‚Üí Ingresos adicionales = [c√°lculo]
  ```

#### Pregunta 4: ¬øQu√© condiciones de datos mejorar√≠an resultados?
- [ ] Listar necesidades de datos:
  ```markdown
  **1. M√°s datos hist√≥ricos:**
  - Actual: 6 meses
  - Ideal: 12-24 meses
  - Beneficio: Capturar estacionalidad, patrones anuales

  **2. Variables externas:**
  - Promociones recibidas (tipo, descuento, fecha)
  - Canal de adquisici√≥n (org√°nico, pagado, referido)
  - Actividad de competencia
  - Beneficio: Explicar variabilidad no capturada (R¬≤ actual vs mejorado)

  **3. Datos comportamentales:**
  - Sesiones en app (frecuencia, duraci√≥n)
  - B√∫squedas realizadas
  - Carritos abandonados
  - Beneficio: Se√±ales tempranas de intenci√≥n de compra

  **4. Nuevas caracter√≠sticas:**
  - Interacciones con soporte (tickets)
  - M√©todos de pago utilizados
  - Ratings/reviews dejados
  - Beneficio: Indicadores de satisfacci√≥n y lealtad

  **5. Menos sesgo:**
  - Actual: Solo usuarios que llegaron a 4ta orden (survival bias)
  - Ideal: Incluir usuarios que abandonaron antes de 4ta orden
  - Beneficio: Modelar churn, entender por qu√© usuarios no crecen
  ```

#### Pregunta 5: ¬øEl mejor modelo es suficiente para el problema de negocio?
- [ ] An√°lisis cr√≠tico:
  ```markdown
  **S√≠, para un MVP (Minimum Viable Product):**

  ‚úÖ **Fortalezas:**
  - AUC > 0.75 permite priorizaci√≥n efectiva de top 20% usuarios
  - Features importantes son accionables (recencia, velocidad)
  - Interpretabilidad alta (Random Forest/XGBoost con feature importance)
  - Reduce incertidumbre vs enfoque aleatorio o basado solo en intuici√≥n

  ‚ö†Ô∏è **Limitaciones:**
  - RMSE de [X.XX] √≥rdenes implica error promedio de ~[X]% en predicci√≥n exacta
  - No captura cambios din√°micos (ej: si usuario recibe promoci√≥n, modelo no se ajusta)
  - Asume que patrones pasados se mantienen (riesgo de concept drift)

  **Suficiencia:**
  - **Para priorizaci√≥n de recursos:** S√ç (distingue bien high vs low growth)
  - **Para predicci√≥n exacta de √≥rdenes:** PARCIAL (√∫til pero con margen de error)
  - **Para decisiones automatizadas:** NO (requiere supervisi√≥n humana)

  **Recomendaci√≥n:**
  - Usar modelo para **scoring y ranking** de usuarios (top 20% ‚Üí alta prioridad)
  - Complementar con reglas de negocio (ej: siempre reactivar usuarios "Fr√≠o" ‚Üí "Perdido")
  - Implementar **monitoreo continuo** de performance
  - **Reentrenar trimestralmente** con datos nuevos
  - Validar con **A/B testing** (grupo con modelo vs grupo control)
  ```

### 7.2 Resumen Ejecutivo
- [ ] Escribir resumen de 1 p√°gina (max 500 palabras):
  ```markdown
  ## Resumen Ejecutivo

  **Problema:**
  [2 oraciones sobre el desaf√≠o de negocio]

  **Enfoque:**
  - An√°lisis exploratorio de 41,667 usuarios (6 meses de datos)
  - Desarrollo de 2 modelos predictivos (clasificaci√≥n + regresi√≥n)
  - Construcci√≥n de dashboard interactivo con sistema de recomendaci√≥n

  **Hallazgos Clave:**
  1. **Recencia es el factor cr√≠tico:** Usuarios activos (‚â§7d) crecen 7x m√°s que inactivos
  2. **Velocidad predice crecimiento:** Usuarios r√°pidos (0-7d a 4ta orden) crecen 2.3x m√°s
  3. **Segmento r_segment002 superior:** Mejor performance en todas las m√©tricas

  **Modelo Desarrollado:**
  - Clasificador: [Algoritmo], AUC-ROC = [X.XX], identifica high-growth users
  - Regresor: [Algoritmo], RMSE = [X.XX], predice √≥rdenes futuras
  - Top features: recencia, velocidad, segmento (coherentes con EDA)

  **Producto Entregado:**
  - Dashboard con 4 m√≥dulos (KPIs, segmentaci√≥n, predicciones, afinidades)
  - Sistema de recomendaci√≥n (prioriza top 20% usuarios por probabilidad de crecimiento)
  - Arquitectura desplegable localmente (Streamlit)

  **Impacto Estimado:**
  - Usuarios activos: +18% (29.7% ‚Üí 35%)
  - √ìrdenes promedio: +16% (6.9 ‚Üí 8.0)
  - CPOI: -15%

  **Pr√≥ximos Pasos:**
  - A/B testing con grupo control
  - Reentrenamiento trimestral
  - Expansi√≥n a otros segmentos de usuarios
  ```

**Archivo a actualizar:**
- `documento/ENTREGA_FINAL.md` (secci√≥n de Conclusiones)

---

## üé¨ FASE 8: Video y Documentaci√≥n Final (D√≠a 7)

**Estado:** ‚è≥ Pendiente
**Objetivo:** Video de 10 min + documento PDF final

### 8.1 Guion del Video (10 minutos m√°ximo)

#### Estructura y Responsables
- [ ] **[00:00 - 01:00] Introducci√≥n** (Ambos)
  - Presentaci√≥n del equipo
  - Problem√°tica de negocio (Engagement team no sabe priorizar recursos)
  - Objetivos del proyecto

- [ ] **[01:00 - 02:30] Datos y Hallazgos Clave** (Juan David)
  - Dataset: 41,667 usuarios, 15 variables, 100/100 calidad
  - 3 hip√≥tesis validadas:
    - Recencia: 7x impacto
    - Velocidad: 2.3x impacto
    - Afinidades: 6 categor√≠as = 80% √≥rdenes
  - Mostrar 2-3 visualizaciones clave

- [ ] **[02:30 - 04:00] Enfoque Anal√≠tico y Modelos** (Juan Esteban)
  - Preparaci√≥n de datos (feature engineering, 25 features finales)
  - Modelos entrenados: RF, XGBoost, LightGBM
  - Mejor modelo: [Algoritmo] con AUC=[X.XX], RMSE=[X.XX]
  - Feature importance: recencia #1, velocidad #2 (validaci√≥n de EDA)

- [ ] **[04:00 - 06:30] Demo del Dashboard** (Juan David - Screen Recording)
  - P√°gina 1: KPIs ejecutivos
  - P√°gina 2: Explorador de segmentos (aplicar filtros)
  - P√°gina 3: **CORE** - Predicci√≥n de usuario ejemplo
    - Input: seleccionar usuario "Tibio"
    - Output: 68% prob de high-growth
    - Recomendaci√≥n: "Alta prioridad, enviar cup√≥n categor√≠a Groceries"
  - P√°gina 4: An√°lisis de afinidades

- [ ] **[06:30 - 08:00] Sistema de Recomendaci√≥n y Arquitectura** (Juan Esteban)
  - L√≥gica de recomendaci√≥n: ranking ‚Üí top 20% ‚Üí budget allocation
  - Diagrama de arquitectura (data ‚Üí model ‚Üí dashboard)
  - Deployment: Streamlit local, opci√≥n cloud

- [ ] **[08:00 - 09:30] Impacto de Negocio y Conclusiones** (Ambos)
  - KPIs esperados: +18% activos, +16% √≥rdenes, -15% CPOI
  - Limitaciones: RMSE implica error, necesita monitoreo
  - Validaci√≥n con 3 stakeholder interactions

- [ ] **[09:30 - 10:00] Pr√≥ximos Pasos** (Ambos)
  - A/B testing en producci√≥n
  - Reentrenamiento trimestral
  - Expansi√≥n a otros segmentos
  - Cierre y agradecimientos

### 8.2 Producci√≥n del Video
- [ ] Grabar segmentos individuales (permite re-grabar si hay errores)
- [ ] Screen recording del dashboard (OBS Studio o Loom)
- [ ] Editar con transiciones suaves (iMovie, DaVinci Resolve, o Camtasia)
- [ ] Agregar:
  - T√≠tulo inicial con nombres y curso
  - Subt√≠tulos en momentos clave (opcional pero ayuda)
  - M√∫sica de fondo sutil (opcional)
- [ ] Exportar en 1080p, formato MP4
- [ ] **CR√çTICO:** Verificar que dura ‚â§10 minutos

**Herramientas sugeridas:**
- Screen recording: OBS Studio (gratis), Loom
- Edici√≥n: DaVinci Resolve (gratis), iMovie (Mac), OpenShot (Linux)
- Conversi√≥n/compresi√≥n: HandBrake

### 8.3 Documento Final PDF
- [ ] Compilar en orden:
  1. Portada (t√≠tulo, autores, fecha, curso)
  2. Tabla de contenidos
  3. **Secci√≥n 1:** Definici√≥n de Problem√°tica (mejorada con feedback)
  4. **Secci√≥n 2:** Ideaci√≥n (con customer journey)
  5. **Secci√≥n 3:** Enfoque √âtico y Responsable
  6. **Secci√≥n 4:** Enfoque Anal√≠tico (tabla de modelos, referencias)
  7. **Secci√≥n 5:** Recolecci√≥n de Datos (con detalles: # usuarios, ventanas)
  8. **Secci√≥n 6:** Entendimiento de Datos (con p-values, effect sizes)
  9. **Secci√≥n 7:** Preparaci√≥n de Datos (pipeline, features, splits) ‚≠ê NUEVO
  10. **Secci√≥n 8:** Modelado y Evaluaci√≥n (3+ algoritmos, m√©tricas) ‚≠ê NUEVO
  11. **Secci√≥n 9:** Producto de Datos (dashboard, arquitectura) ‚≠ê NUEVO
  12. **Secci√≥n 10:** Stakeholder Feedback (bit√°cora 3 interacciones) ‚≠ê NUEVO
  13. **Secci√≥n 11:** Conclusiones (5 preguntas + resumen ejecutivo) ‚≠ê NUEVO
  14. Referencias

- [ ] Formato:
  - Arial 12pt
  - M√°ximo 10 p√°ginas (sin contar portada, tabla contenidos, referencias)
  - Single column
  - Figuras numeradas con captions
  - Tablas numeradas con captions

- [ ] Exportar como PDF desde Word/Google Docs/LaTeX
- [ ] Nombre archivo: `ENTREGA_FINAL_Valencia_Cuellar.pdf`

### 8.4 Checklist Final Pre-Entrega
- [ ] Video:
  - [ ] Duraci√≥n ‚â§ 10 minutos
  - [ ] Ambos integrantes participan
  - [ ] Audio claro (sin ruido de fondo)
  - [ ] Pantalla legible en screen recording
  - [ ] Formato: MP4, 1080p
  - [ ] Nombre: `VideoEntregaFinal_Valencia_Cuellar.mp4`

- [ ] Documento:
  - [ ] Todas las secciones completas (11 secciones)
  - [ ] Feedback del profesor incorporado
  - [ ] Figuras y tablas numeradas
  - [ ] Referencias en formato APA/IEEE
  - [ ] M√°ximo 10 p√°ginas (contenido principal)
  - [ ] PDF exportado correctamente

- [ ] C√≥digo:
  - [ ] Notebooks ejecutables sin errores (.ipynb)
  - [ ] Modelos guardados (.pkl files)
  - [ ] Dashboard funcional (app.py)
  - [ ] requirements.txt actualizado
  - [ ] README.md con instrucciones de ejecuci√≥n

- [ ] Repositorio GitHub:
  - [ ] Todos los archivos subidos
  - [ ] README.md actualizado con info de entrega final
  - [ ] .gitignore apropiado (no subir datos sensibles)
  - [ ] Estructura de carpetas clara

**Archivos finales a entregar:**
- `documento/ENTREGA_FINAL_Valencia_Cuellar.pdf`
- `video/VideoEntregaFinal_Valencia_Cuellar.mp4`
- Link a repositorio GitHub actualizado

---

## üìã CHECKLIST GENERAL DE ENTREGABLES

### Documentaci√≥n
- [ ] `documento/ENTREGA_FINAL_Valencia_Cuellar.pdf` (max 10 p√°ginas)
- [ ] `documento/BITACORA_STAKEHOLDERS.md` (3 interacciones)
- [ ] `documento/figuras/customer_journey.png`
- [ ] `documento/figuras/pipeline_preparacion.png`
- [ ] `documento/figuras/arquitectura_producto.png`

### Notebooks
- [ ] `notebooks/01_data_preparation.ipynb` (feature engineering, splits)
- [ ] `notebooks/02_model_training_classification.ipynb`
- [ ] `notebooks/03_model_training_regression.ipynb`
- [ ] `notebooks/04_model_evaluation.ipynb`
- [ ] `notebooks/entendimiento_datos.ipynb` (ya existe, mantener)

### Modelos
- [ ] `models/feature_engineering_pipeline.pkl`
- [ ] `models/rf_classifier.pkl`
- [ ] `models/xgb_classifier.pkl`
- [ ] `models/lgbm_classifier.pkl`
- [ ] `models/rf_regressor.pkl`
- [ ] `models/xgb_regressor.pkl`
- [ ] `models/ridge_regressor.pkl`
- [ ] `models/best_classifier.pkl` (mejor seleccionado)
- [ ] `models/best_regressor.pkl` (mejor seleccionado)

### Datos Procesados
- [ ] `data/processed/train.csv`
- [ ] `data/processed/val.csv`
- [ ] `data/processed/test.csv`

### Dashboard
- [ ] `dashboard/app.py` (aplicaci√≥n Streamlit completa)
- [ ] `dashboard/utils.py` (funciones helper)
- [ ] `dashboard/requirements.txt`
- [ ] `dashboard/README.md` (instrucciones deployment)

### Video y Presentaci√≥n
- [ ] `video/VideoEntregaFinal_Valencia_Cuellar.mp4` (‚â§10 min)
- [ ] `video/PresentacionFinal.pdf` (slides - opcional)

### Otros
- [ ] `README.md` actualizado con secci√≥n de entrega final
- [ ] `PLAN_ENTREGA_FINAL.md` (este archivo, actualizado con progreso)

---

## üóíÔ∏è NOTAS Y DECISIONES IMPORTANTES

### Decisiones T√©cnicas

**[2025-11-23] Sesi√≥n 1 - Mejora de Documentaci√≥n:**
- **Decisi√≥n:** Crear documento ENTREGA_FINAL.md desde cero incorporando TODO el feedback del profesor
- **Justificaci√≥n:** M√°s eficiente que editar secciones individuales del documento original
- **Resultado:** 1,353 l√≠neas, 6 secciones completas (de 11 totales)

**[2025-11-23] Mejoras Implementadas en Documentaci√≥n:**
- **Problem√°tica (8.5/10 ‚Üí objetivo 10/10):**
  - ‚úÖ KPIs definidos con tablas detalladas (recencia 5 categor√≠as, CPOI con f√≥rmula)
  - ‚úÖ Tabla baseline vs objetivo con mejoras esperadas (+18% activos, +16% delta, -15% CPOI)
  - ‚úÖ Impacto financiero estimado: $870,000/a√±o
  - ‚úÖ Eliminadas referencias a fechas espec√≠ficas (generalizable a cualquier cohorte)

- **Ideaci√≥n (7.5/10 ‚Üí objetivo 10/10):**
  - ‚úÖ Customer journey textual con ventanas cr√≠ticas de intervenci√≥n
  - ‚úÖ Explicaci√≥n detallada de por qu√© 30-90 d√≠as (ventana presupuestaria)
  - ‚úÖ Aclaraci√≥n de afinidades din√°micas (calculadas from user history)
  - ‚úÖ Mockup mejorado en ASCII art mostrando predicci√≥n ‚Üí recomendaci√≥n ‚Üí acci√≥n
  - ‚úÖ Flujo completo: Predicci√≥n ‚Üí Dashboard ‚Üí Acci√≥n

- **Enfoque Anal√≠tico (10.875/15 ‚Üí objetivo 15/15):**
  - ‚úÖ Tabla completa de modelos (tipo, variable objetivo, algoritmos, m√©tricas, uso negocio)
  - ‚úÖ Justificaci√≥n de 2 modelos (clasificaci√≥n para decisiones binarias, regresi√≥n para planificaci√≥n)
  - ‚úÖ M√©tricas de clustering especificadas (Silhouette, Davies-Bouldin, Calinski-Harabasz)
  - ‚úÖ 4 referencias acad√©micas citadas (Verbeke, Ascarza, Neslin, Hudge)
  - ‚úÖ Proceso de experimentaci√≥n paso a paso (GridSearchCV, 5-fold CV, hold-out test)

- **Recolecci√≥n de Datos (9/10 ‚Üí objetivo 10/10):**
  - ‚úÖ Resumen dataset agregado: 41,667 usuarios, 7.2 √≥rdenes/usuario, ventana 6 meses

- **Entendimiento de Datos (29.75/35 ‚Üí objetivo 35/35):**
  - ‚úÖ Tabla de resumen del dataset en secci√≥n 6.1
  - ‚úÖ P-valores expl√≠citos en TODAS las pruebas (p < 0.001 reportado)
  - ‚úÖ Effect sizes reportados (Œ∑¬≤ = 0.073 para ANOVA, r¬≤ = 0.040 para correlaci√≥n)
  - ‚úÖ Grupos ANOVA especificados (5 categor√≠as: Activo, Semi-Activo, Tibio, Fr√≠o, Perdido)
  - ‚úÖ Las 6 categor√≠as principales listadas con nombres y porcentajes
  - ‚úÖ Tests no param√©tricos agregados (Kruskal-Wallis, Spearman) para robustez

### Problemas Encontrados y Soluciones

**[2025-11-23] Problema: Dataset no encontrado al ejecutar scripts**
- **Problema:** Scripts en `scripts/` buscan dataset en `../dataset_protegido (1).csv` pero ruta relativa fall√≥
- **Soluci√≥n:** Usar informaci√≥n existente de Primera_Entrega_Proyecto_Final.md en vez de re-ejecutar scripts
- **Resultado:** Documentaci√≥n completada sin re-ejecutar an√°lisis (datos ya validados en primera entrega)

### Aprendizajes

**[2025-11-23] Aprendizajes de la Sesi√≥n 1:**
- Incorporar feedback del profesor requiere reescritura sustancial de secciones (no solo ediciones menores)
- La secci√≥n de Enfoque Anal√≠tico necesitaba el mayor refuerzo (10.875/15) ‚Üí ahora con tabla de modelos, referencias acad√©micas, y m√©tricas de clustering
- Agregar p-values y effect sizes hace la documentaci√≥n mucho m√°s robusta estad√≠sticamente
- Especificar grupos comparados en ANOVA es cr√≠tico para reproducibilidad
- Customer journey y mockups mejorados ayudan a conectar predicci√≥n ‚Üí acci√≥n

**[2025-11-23] Aprendizajes de la Sesi√≥n 2 - Fase 2 Preparaci√≥n de Datos:**
- Feature engineering extensivo: 12 features nuevos derivados (afinidades, temporales, transformaciones)
- One-hot encoding genera 40 features binarios desde 5 categ√≥ricas (drop='first' evita multicolinealidad)
- StandardScaler cr√≠tico para modelos basados en distancia (futuros: XGBoost, Random Forest)
- Split estratificado preserva distribuci√≥n de high_growth (20.36% en todos los conjuntos)
- Serializar pipeline (scaler + encoder) permite aplicar mismas transformaciones en producci√≥n
- Log-transform reduce asimetr√≠a de variables con skewness > 3
- Shannon entropy captura diversidad de afinidades (m√°s robusto que conteo simple)
- Mantener outliers (power users con >14 √≥rdenes) es decisi√≥n de negocio, no t√©cnica
- Total de 51 features finales (11 num√©ricos escalados + 40 categ√≥ricos encoded)
- Datasets generados: 25K train, 8.3K val, 8.3K test (16 MB total)
- Diagrama de pipeline con Mermaid facilita comunicaci√≥n y reproducibilidad

---

## üìû Contactos y Recursos

**Equipo:**
- Juan David Valencia ‚Äì 201728857
- Juan Esteban Cuellar ‚Äì 202014258

**Curso:**
- MINE-4101: Ciencia de Datos Aplicada
- Semestre: 2025-20
- Universidad de los Andes

**Recursos:**
- Repositorio: github.com/iGotty/Proyecto_DS_valencia_cuellar
- Dataset: `dataset_protegido (1).csv` (15 MB, 41,667 users)
- Documentaci√≥n anterior: `documento/PRIMERA ENTREGA...pdf`

---

## üéØ Siguiente Acci√≥n Inmediata

**FASE 1 COMPLETADA ‚úÖ**
**FASE 2 COMPLETADA ‚úÖ**

**PR√ìXIMO PASO:** Fase 4 - Construcci√≥n de Modelos (20% de la nota)

**Nota:** Fase 3 (Estrategia de Validaci√≥n - 5%) se puede incorporar en el notebook de modelado como secci√≥n inicial.

**Acciones para Fase 4:**
1. Crear notebook `notebooks/02_model_training_classification.ipynb`
2. Cargar datasets procesados desde `data/processed/`
3. Entrenar modelo de clasificaci√≥n (high_growth) con 3 algoritmos:
   - Random Forest Classifier
   - XGBoost Classifier
   - LightGBM Classifier
4. Optimizaci√≥n de hiperpar√°metros con GridSearchCV/RandomizedSearchCV
5. Evaluaci√≥n cuantitativa: AUC-ROC, F1-score, Precision@20%, matrices de confusi√≥n
6. Evaluaci√≥n cualitativa: an√°lisis de feature importance, casos mal clasificados
7. Selecci√≥n del mejor modelo seg√∫n m√©tricas
8. Guardar mejor modelo: `models/best_classifier.pkl`

**Opcional (si hay tiempo):**
- Crear notebook de regresi√≥n `02b_model_training_regression.ipynb`
- Entrenar modelos de regresi√≥n (delta_orders) con RF Regressor, XGBoost Regressor, Ridge

**Prioridad:** ALTA - Backbone del producto de datos

**Meta de m√©tricas:**
- AUC-ROC > 0.75 (target definido en enfoque anal√≠tico)
- F1-score > 0.65
- Precision@20% > 0.80 (para targeting efectivo)

---

*√öltima actualizaci√≥n: 2025-11-23 por Claude Code*
*Estado general: 37.5% completado (Fase 1 y 2 de 8)*
