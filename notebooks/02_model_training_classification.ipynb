{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Entrenamiento de Modelos de Clasificaci√≥n\n",
    "\n",
    "**Proyecto:** Entrega Final - Optimizaci√≥n de Estrategias de Retenci√≥n\n",
    "\n",
    "**Autores:** Juan David Valencia, Juan Esteban Cuellar\n",
    "\n",
    "**Fecha:** Noviembre 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Este notebook implementa el **entrenamiento, optimizaci√≥n y evaluaci√≥n de modelos de clasificaci√≥n** para predecir usuarios con alto potencial de crecimiento (`high_growth`).\n",
    "\n",
    "**Problema de Negocio:** Identificar qu√© usuarios tienen mayor probabilidad de convertirse en usuarios de alto crecimiento (delta_orders > 8) para optimizar asignaci√≥n de presupuesto promocional.\n",
    "\n",
    "**Variable Objetivo:** `high_growth` (binaria: 1 si delta_orders > 8, 0 si no)\n",
    "\n",
    "**Algoritmos a Comparar:**\n",
    "1. Random Forest Classifier\n",
    "2. XGBoost Classifier\n",
    "3. LightGBM Classifier\n",
    "\n",
    "**M√©tricas de Evaluaci√≥n:**\n",
    "- **AUC-ROC** (objetivo: > 0.75) - M√©trica principal\n",
    "- **F1-Score** (objetivo: > 0.65)\n",
    "- **Precision@20%** (objetivo: > 0.80) - Para targeting top-20% usuarios\n",
    "- Matriz de confusi√≥n\n",
    "- Curvas ROC y Precision-Recall\n",
    "\n",
    "**Entrada:** Datasets procesados de `data/processed/`\n",
    "\n",
    "**Salida:** \n",
    "- Mejor modelo entrenado: `models/best_classifier.pkl`\n",
    "- Reporte de evaluaci√≥n: `models/classification_report.json`\n",
    "- Visualizaciones: `documento/figuras/model_*.png`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estrategia de Validaci√≥n y Experimentaci√≥n (Fase 3 - 5%)\n",
    "\n",
    "### 1.1 Estrategia de Experimentaci√≥n\n",
    "\n",
    "**Proceso de Modelado:**\n",
    "\n",
    "1. **Entrenamiento Inicial:**\n",
    "   - Entrenar m√∫ltiples algoritmos (RF, XGBoost, LightGBM) en conjunto **TRAIN**\n",
    "   - Usar configuraciones baseline para establecer l√≠nea base de desempe√±o\n",
    "\n",
    "2. **Optimizaci√≥n de Hiperpar√°metros:**\n",
    "   - Usar **5-fold Cross-Validation** en conjunto TRAIN para optimizar hiperpar√°metros\n",
    "   - T√©cnica: **GridSearchCV** (exploraci√≥n exhaustiva del espacio de par√°metros)\n",
    "   - M√©trica de optimizaci√≥n: **AUC-ROC** (balance entre sensibilidad y especificidad)\n",
    "\n",
    "3. **Selecci√≥n de Modelo:**\n",
    "   - Evaluar mejor configuraci√≥n de cada algoritmo en conjunto **VALIDATION**\n",
    "   - Comparar modelos usando m√©tricas m√∫ltiples (AUC-ROC, F1, Precision@20%)\n",
    "   - Seleccionar mejor modelo basado en criterios de negocio + m√©tricas estad√≠sticas\n",
    "\n",
    "4. **Evaluaci√≥n Final:**\n",
    "   - Evaluar mejor modelo en conjunto **TEST** (1 sola vez, sin reentrenamiento)\n",
    "   - Reportar m√©tricas finales + intervalos de confianza\n",
    "   - An√°lisis cualitativo: feature importance, casos mal clasificados\n",
    "\n",
    "### 1.2 Justificaci√≥n de la Estrategia\n",
    "\n",
    "- **5-fold CV:** Balance entre robustez (m√∫ltiples folds) y costo computacional\n",
    "- **GridSearchCV:** Garantiza exploraci√≥n sistem√°tica del espacio de hiperpar√°metros\n",
    "- **Hold-out test set:** Evaluaci√≥n no sesgada del desempe√±o final (conjunto nunca visto)\n",
    "- **AUC-ROC como m√©trica primaria:** Insensible a desbalance de clases (20% high-growth)\n",
    "\n",
    "### 1.3 Verificaci√≥n de Distribuciones\n",
    "\n",
    "Verificaremos que los conjuntos Train/Val/Test preservan las distribuciones de las variables clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports completados\n",
      "üìÖ Fecha de ejecuci√≥n: 2025-11-27 09:44:28\n",
      "\n",
      "üì¶ Versiones:\n",
      "   - XGBoost: 3.1.2\n",
      "   - LightGBM: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn - Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, recall_score, accuracy_score,\n",
    "    confusion_matrix, classification_report, roc_curve, precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# XGBoost y LightGBM\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Configuraci√≥n\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Imports completados\")\n",
    "print(f\"üìÖ Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nüì¶ Versiones:\")\n",
    "print(f\"   - XGBoost: {xgb.__version__}\")\n",
    "print(f\"   - LightGBM: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando datasets procesados...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2357765698.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üìÇ Cargando datasets procesados...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Cargar datasets procesados\n",
    "TRAIN_PATH = '../data/processed/train.csv'\n",
    "VAL_PATH = '../data/processed/val.csv'\n",
    "TEST_PATH = '../data/processed/test.csv'\n",
    "\n",
    "print(\"üìÇ Cargando datasets procesados...\\n\")\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(f\"‚úÖ Train: {train_df.shape[0]:,} usuarios √ó {train_df.shape[1]} features\")\n",
    "print(f\"‚úÖ Validation: {val_df.shape[0]:,} usuarios √ó {val_df.shape[1]} features\")\n",
    "print(f\"‚úÖ Test: {test_df.shape[0]:,} usuarios √ó {test_df.shape[1]} features\")\n",
    "\n",
    "print(f\"\\nüìä Distribuci√≥n de high_growth:\")\n",
    "print(f\"   - Train: {train_df['high_growth'].mean()*100:.2f}% positivos\")\n",
    "print(f\"   - Validation: {val_df['high_growth'].mean()*100:.2f}% positivos\")\n",
    "print(f\"   - Test: {test_df['high_growth'].mean()*100:.2f}% positivos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Features para modelado: 51\n",
      "\n",
      "üìã Primeras 10 features:\n",
      "    1. total_orders_tmenos1\n",
      "    2. efo_to_four\n",
      "    3. log_efo_to_four\n",
      "    4. category_diversity\n",
      "    5. num_categories\n",
      "    6. num_shops\n",
      "    7. num_brands\n",
      "    8. brand001_ratio\n",
      "    9. days_since_first_order\n",
      "   10. orders_per_day\n",
      "   ... (41 features m√°s)\n",
      "\n",
      "‚úÖ X_train: (25000, 51)\n",
      "‚úÖ y_train: (25000,) (positivos: 5,090 = 20.36%)\n"
     ]
    }
   ],
   "source": [
    "# Separar features y targets\n",
    "# Recordar: uid, high_growth, delta_orders no son features\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col not in ['uid', 'high_growth', 'delta_orders']]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['high_growth']\n",
    "\n",
    "X_val = val_df[feature_cols]\n",
    "y_val = val_df['high_growth']\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['high_growth']\n",
    "\n",
    "print(f\"üìä Features para modelado: {len(feature_cols)}\")\n",
    "print(f\"\\nüìã Primeras 10 features:\")\n",
    "for i, feat in enumerate(feature_cols[:10], 1):\n",
    "    print(f\"   {i:2d}. {feat}\")\n",
    "print(f\"   ... ({len(feature_cols) - 10} features m√°s)\")\n",
    "\n",
    "print(f\"\\n‚úÖ X_train: {X_train.shape}\")\n",
    "print(f\"‚úÖ y_train: {y_train.shape} (positivos: {y_train.sum():,} = {y_train.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Verificaci√≥n de Distribuciones\n",
    "\n",
    "Verificamos que las distribuciones se preservan entre Train/Val/Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificando preservaci√≥n de distribuciones...\n",
      "\n",
      "üìä Tabla de Contingencia (high_growth):\n",
      "             Train  Validation  Test\n",
      "high_growth                         \n",
      "0            19910        6637  6637\n",
      "1             5090        1696  1697\n",
      "\n",
      "üìà Test Chi-Cuadrado:\n",
      "   - Chi¬≤ = 0.0003\n",
      "   - P-valor = 0.9999\n",
      "   - Conclusi√≥n: ‚úÖ Distribuciones preservadas (p > 0.05)\n",
      "\n",
      "üìä Estad√≠sticas de delta_orders:\n",
      "              Train   Validation         Test\n",
      "count  25000.000000  8333.000000  8334.000000\n",
      "mean       6.846280     6.840034     6.888649\n",
      "std        4.870811     5.105109     5.063934\n",
      "min        1.000000     1.000000     1.000000\n",
      "25%        4.000000     4.000000     4.000000\n",
      "50%        5.000000     5.000000     5.000000\n",
      "75%        8.000000     8.000000     8.000000\n",
      "max       95.000000   108.000000    65.000000\n",
      "\n",
      "‚úÖ Verificaci√≥n completada: Distribuciones adecuadas para modelado\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "print(\"üîç Verificando preservaci√≥n de distribuciones...\\n\")\n",
    "\n",
    "# Verificar high_growth\n",
    "contingency_table = pd.DataFrame({\n",
    "    'Train': y_train.value_counts(sort=False),\n",
    "    'Validation': y_val.value_counts(sort=False),\n",
    "    'Test': y_test.value_counts(sort=False)\n",
    "})\n",
    "\n",
    "print(\"üìä Tabla de Contingencia (high_growth):\")\n",
    "print(contingency_table)\n",
    "\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table.values)\n",
    "\n",
    "print(f\"\\nüìà Test Chi-Cuadrado:\")\n",
    "print(f\"   - Chi¬≤ = {chi2:.4f}\")\n",
    "print(f\"   - P-valor = {p_value:.4f}\")\n",
    "print(f\"   - Conclusi√≥n: {'‚úÖ Distribuciones preservadas (p > 0.05)' if p_value > 0.05 else '‚ö†Ô∏è Posible diferencia en distribuciones'}\")\n",
    "\n",
    "# Verificar distribuci√≥n de delta_orders (target de regresi√≥n)\n",
    "print(f\"\\nüìä Estad√≠sticas de delta_orders:\")\n",
    "stats_df = pd.DataFrame({\n",
    "    'Train': train_df['delta_orders'].describe(),\n",
    "    'Validation': val_df['delta_orders'].describe(),\n",
    "    'Test': test_df['delta_orders'].describe()\n",
    "})\n",
    "print(stats_df)\n",
    "\n",
    "print(f\"\\n‚úÖ Verificaci√≥n completada: Distribuciones adecuadas para modelado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelo Baseline: Random Forest Classifier\n",
    "\n",
    "Comenzamos con Random Forest como modelo baseline por su robustez y facilidad de interpretaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ RANDOM FOREST CLASSIFIER - Configuraci√≥n Baseline\n",
      "\n",
      "‚è≥ Entrenando Random Forest baseline...\n",
      "\n",
      "üìä M√©tricas Random Forest (Baseline):\n",
      "\n",
      "============================================================\n",
      "M√©trica                             Train      Validation\n",
      "============================================================\n",
      "AUC-ROC                            0.9935          0.9906\n",
      "F1-Score                           0.8812          0.8752\n",
      "Precision                          0.8105          0.8031\n",
      "Recall                             0.9654          0.9617\n",
      "Accuracy                           0.9470          0.9442\n",
      "============================================================\n",
      "\n",
      "‚úÖ Random Forest baseline entrenado\n"
     ]
    }
   ],
   "source": [
    "print(\"üå≤ RANDOM FOREST CLASSIFIER - Configuraci√≥n Baseline\\n\")\n",
    "\n",
    "# Configuraci√≥n baseline\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'  # Manejar desbalance de clases\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Entrenando Random Forest baseline...\")\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred_rf = rf_baseline.predict(X_train)\n",
    "y_train_proba_rf = rf_baseline.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_val_pred_rf = rf_baseline.predict(X_val)\n",
    "y_val_proba_rf = rf_baseline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "print(f\"\\nüìä M√©tricas Random Forest (Baseline):\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"{'M√©trica':<25} {'Train':>15} {'Validation':>15}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'AUC-ROC':<25} {roc_auc_score(y_train, y_train_proba_rf):>15.4f} {roc_auc_score(y_val, y_val_proba_rf):>15.4f}\")\n",
    "print(f\"{'F1-Score':<25} {f1_score(y_train, y_train_pred_rf):>15.4f} {f1_score(y_val, y_val_pred_rf):>15.4f}\")\n",
    "print(f\"{'Precision':<25} {precision_score(y_train, y_train_pred_rf):>15.4f} {precision_score(y_val, y_val_pred_rf):>15.4f}\")\n",
    "print(f\"{'Recall':<25} {recall_score(y_train, y_train_pred_rf):>15.4f} {recall_score(y_val, y_val_pred_rf):>15.4f}\")\n",
    "print(f\"{'Accuracy':<25} {accuracy_score(y_train, y_train_pred_rf):>15.4f} {accuracy_score(y_val, y_val_pred_rf):>15.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Random Forest baseline entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Optimizaci√≥n de Hiperpar√°metros - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - Random Forest\n",
      "\n",
      "üìã Grid de b√∫squeda:\n",
      "   - n_estimators: [100, 200, 300]\n",
      "   - max_depth: [10, 15, 20, None]\n",
      "   - min_samples_split: [10, 20, 30]\n",
      "   - min_samples_leaf: [5, 10, 15]\n",
      "   - max_features: ['sqrt', 'log2']\n",
      "\n",
      "üî¢ Total de combinaciones: 216\n",
      "‚è±Ô∏è Tiempo estimado: ~18 minutos (con 5-fold CV)\n",
      "\n",
      "‚è≥ Iniciando GridSearchCV para Random Forest...\n",
      "   (Esto puede tomar varios minutos)\n",
      "\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "‚úÖ Optimizaci√≥n completada!\n",
      "\n",
      "üèÜ Mejores hiperpar√°metros:\n",
      "   - max_depth: None\n",
      "   - max_features: sqrt\n",
      "   - min_samples_leaf: 5\n",
      "   - min_samples_split: 10\n",
      "   - n_estimators: 300\n",
      "\n",
      "üìä Mejor AUC-ROC (5-fold CV): 0.9942\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - Random Forest\\n\")\n",
    "\n",
    "# Grid de hiperpar√°metros\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, 20, None],\n",
    "    'min_samples_split': [10, 20, 30],\n",
    "    'min_samples_leaf': [5, 10, 15],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "print(f\"üìã Grid de b√∫squeda:\")\n",
    "for param, values in param_grid_rf.items():\n",
    "    print(f\"   - {param}: {values}\")\n",
    "\n",
    "total_combinations = np.prod([len(v) for v in param_grid_rf.values()])\n",
    "print(f\"\\nüî¢ Total de combinaciones: {total_combinations:,}\")\n",
    "print(f\"‚è±Ô∏è Tiempo estimado: ~{total_combinations * 5 // 60} minutos (con 5-fold CV)\\n\")\n",
    "\n",
    "# GridSearchCV\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced'),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Iniciando GridSearchCV para Random Forest...\")\n",
    "print(\"   (Esto puede tomar varios minutos)\\n\")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Optimizaci√≥n completada!\")\n",
    "print(f\"\\nüèÜ Mejores hiperpar√°metros:\")\n",
    "for param, value in rf_grid.best_params_.items():\n",
    "    print(f\"   - {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä Mejor AUC-ROC (5-fold CV): {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Guardar mejor modelo\n",
    "best_rf = rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä M√©tricas Random Forest (Optimizado) en Validation:\n",
      "   - AUC-ROC: 0.9953\n",
      "   - F1-Score: 0.9179\n",
      "   - Precision: 0.8774\n",
      "   - Recall: 0.9623\n",
      "   - Precision@20%: 0.9334\n"
     ]
    }
   ],
   "source": [
    "# Evaluar mejor Random Forest en validation\n",
    "y_val_pred_rf_opt = best_rf.predict(X_val)\n",
    "y_val_proba_rf_opt = best_rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"üìä M√©tricas Random Forest (Optimizado) en Validation:\")\n",
    "print(f\"   - AUC-ROC: {roc_auc_score(y_val, y_val_proba_rf_opt):.4f}\")\n",
    "print(f\"   - F1-Score: {f1_score(y_val, y_val_pred_rf_opt):.4f}\")\n",
    "print(f\"   - Precision: {precision_score(y_val, y_val_pred_rf_opt):.4f}\")\n",
    "print(f\"   - Recall: {recall_score(y_val, y_val_pred_rf_opt):.4f}\")\n",
    "\n",
    "# Precision@20%\n",
    "top_20_idx = np.argsort(y_val_proba_rf_opt)[-int(len(y_val) * 0.20):]\n",
    "precision_at_20 = y_val.iloc[top_20_idx].mean()\n",
    "print(f\"   - Precision@20%: {precision_at_20:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo 2: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ XGBOOST CLASSIFIER - Configuraci√≥n Baseline\n",
      "\n",
      "‚öñÔ∏è Scale pos weight: 3.91\n",
      "‚è≥ Entrenando XGBoost baseline...\n",
      "\n",
      "üìä M√©tricas XGBoost (Baseline) en Validation:\n",
      "   - AUC-ROC: 0.9999\n",
      "   - F1-Score: 0.9965\n",
      "   - Precision: 0.9965\n",
      "   - Recall: 0.9965\n",
      "\n",
      "‚úÖ XGBoost baseline entrenado\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ XGBOOST CLASSIFIER - Configuraci√≥n Baseline\\n\")\n",
    "\n",
    "# Calcular scale_pos_weight para manejar desbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"‚öñÔ∏è Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# Baseline\n",
    "xgb_baseline = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Entrenando XGBoost baseline...\")\n",
    "xgb_baseline.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_xgb = xgb_baseline.predict(X_val)\n",
    "y_val_proba_xgb = xgb_baseline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"\\nüìä M√©tricas XGBoost (Baseline) en Validation:\")\n",
    "print(f\"   - AUC-ROC: {roc_auc_score(y_val, y_val_proba_xgb):.4f}\")\n",
    "print(f\"   - F1-Score: {f1_score(y_val, y_val_pred_xgb):.4f}\")\n",
    "print(f\"   - Precision: {precision_score(y_val, y_val_pred_xgb):.4f}\")\n",
    "print(f\"   - Recall: {recall_score(y_val, y_val_pred_xgb):.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ XGBoost baseline entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Optimizaci√≥n de Hiperpar√°metros - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - XGBoost\n",
      "\n",
      "üìã Grid de b√∫squeda:\n",
      "   - n_estimators: [100, 200, 300]\n",
      "   - max_depth: [4, 6, 8, 10]\n",
      "   - learning_rate: [0.01, 0.05, 0.1]\n",
      "   - subsample: [0.7, 0.8, 0.9]\n",
      "   - colsample_bytree: [0.7, 0.8, 0.9]\n",
      "\n",
      "üî¢ Total de combinaciones: 324\n",
      "‚è±Ô∏è Tiempo estimado: ~16 minutos\n",
      "\n",
      "‚è≥ Iniciando GridSearchCV para XGBoost...\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "\n",
      "‚úÖ Optimizaci√≥n completada!\n",
      "\n",
      "üèÜ Mejores hiperpar√°metros:\n",
      "   - colsample_bytree: 0.9\n",
      "   - learning_rate: 0.1\n",
      "   - max_depth: 8\n",
      "   - n_estimators: 300\n",
      "   - subsample: 0.9\n",
      "\n",
      "üìä Mejor AUC-ROC (5-fold CV): 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - XGBoost\\n\")\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "print(f\"üìã Grid de b√∫squeda:\")\n",
    "for param, values in param_grid_xgb.items():\n",
    "    print(f\"   - {param}: {values}\")\n",
    "\n",
    "total_combinations = np.prod([len(v) for v in param_grid_xgb.values()])\n",
    "print(f\"\\nüî¢ Total de combinaciones: {total_combinations:,}\")\n",
    "print(f\"‚è±Ô∏è Tiempo estimado: ~{total_combinations * 3 // 60} minutos\\n\")\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb.XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    param_grid=param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Iniciando GridSearchCV para XGBoost...\")\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Optimizaci√≥n completada!\")\n",
    "print(f\"\\nüèÜ Mejores hiperpar√°metros:\")\n",
    "for param, value in xgb_grid.best_params_.items():\n",
    "    print(f\"   - {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä Mejor AUC-ROC (5-fold CV): {xgb_grid.best_score_:.4f}\")\n",
    "\n",
    "best_xgb = xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä M√©tricas XGBoost (Optimizado) en Validation:\n",
      "   - AUC-ROC: 1.0000\n",
      "   - F1-Score: 0.9982\n",
      "   - Precision: 0.9982\n",
      "   - Recall: 0.9982\n",
      "   - Precision@20%: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluar mejor XGBoost en validation\n",
    "y_val_pred_xgb_opt = best_xgb.predict(X_val)\n",
    "y_val_proba_xgb_opt = best_xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"üìä M√©tricas XGBoost (Optimizado) en Validation:\")\n",
    "print(f\"   - AUC-ROC: {roc_auc_score(y_val, y_val_proba_xgb_opt):.4f}\")\n",
    "print(f\"   - F1-Score: {f1_score(y_val, y_val_pred_xgb_opt):.4f}\")\n",
    "print(f\"   - Precision: {precision_score(y_val, y_val_pred_xgb_opt):.4f}\")\n",
    "print(f\"   - Recall: {recall_score(y_val, y_val_pred_xgb_opt):.4f}\")\n",
    "\n",
    "# Precision@20%\n",
    "top_20_idx_xgb = np.argsort(y_val_proba_xgb_opt)[-int(len(y_val) * 0.20):]\n",
    "precision_at_20_xgb = y_val.iloc[top_20_idx_xgb].mean()\n",
    "print(f\"   - Precision@20%: {precision_at_20_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo 3: LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° LIGHTGBM CLASSIFIER - Configuraci√≥n Baseline\n",
      "\n",
      "‚è≥ Entrenando LightGBM baseline...\n",
      "\n",
      "üìä M√©tricas LightGBM (Baseline) en Validation:\n",
      "   - AUC-ROC: 0.9999\n",
      "   - F1-Score: 0.9988\n",
      "   - Precision: 0.9994\n",
      "   - Recall: 0.9982\n",
      "\n",
      "‚úÖ LightGBM baseline entrenado\n"
     ]
    }
   ],
   "source": [
    "print(\"‚ö° LIGHTGBM CLASSIFIER - Configuraci√≥n Baseline\\n\")\n",
    "\n",
    "# Baseline\n",
    "lgb_baseline = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Entrenando LightGBM baseline...\")\n",
    "lgb_baseline.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_lgb = lgb_baseline.predict(X_val)\n",
    "y_val_proba_lgb = lgb_baseline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"\\nüìä M√©tricas LightGBM (Baseline) en Validation:\")\n",
    "print(f\"   - AUC-ROC: {roc_auc_score(y_val, y_val_proba_lgb):.4f}\")\n",
    "print(f\"   - F1-Score: {f1_score(y_val, y_val_pred_lgb):.4f}\")\n",
    "print(f\"   - Precision: {precision_score(y_val, y_val_pred_lgb):.4f}\")\n",
    "print(f\"   - Recall: {recall_score(y_val, y_val_pred_lgb):.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ LightGBM baseline entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Optimizaci√≥n de Hiperpar√°metros - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - LightGBM\n",
      "\n",
      "üìã Grid de b√∫squeda:\n",
      "   - n_estimators: [100, 200, 300]\n",
      "   - max_depth: [8, 10, 15, -1]\n",
      "   - learning_rate: [0.01, 0.05, 0.1]\n",
      "   - num_leaves: [31, 50, 70]\n",
      "   - subsample: [0.7, 0.8, 0.9]\n",
      "   - colsample_bytree: [0.7, 0.8, 0.9]\n",
      "\n",
      "üî¢ Total de combinaciones: 972\n",
      "‚è±Ô∏è Tiempo estimado: ~32 minutos\n",
      "\n",
      "‚è≥ Iniciando GridSearchCV para LightGBM...\n",
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     20\u001b[39m lgb_grid = GridSearchCV(\n\u001b[32m     21\u001b[39m     lgb.LGBMClassifier(\n\u001b[32m     22\u001b[39m         scale_pos_weight=scale_pos_weight,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     32\u001b[39m )\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚è≥ Iniciando GridSearchCV para LightGBM...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mlgb_grid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Optimizaci√≥n completada!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müèÜ Mejores hiperpar√°metros:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Projects/Proyecto_DS/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Projects/Proyecto_DS/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Projects/Proyecto_DS/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Projects/Proyecto_DS/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Projects/Proyecto_DS/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Projects/Proyecto_DS/.venv/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Projects/Proyecto_DS/.venv/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Projects/Proyecto_DS/.venv/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"üîß OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - LightGBM\\n\")\n",
    "\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [8, 10, 15, -1],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "print(f\"üìã Grid de b√∫squeda:\")\n",
    "for param, values in param_grid_lgb.items():\n",
    "    print(f\"   - {param}: {values}\")\n",
    "\n",
    "total_combinations = np.prod([len(v) for v in param_grid_lgb.values()])\n",
    "print(f\"\\nüî¢ Total de combinaciones: {total_combinations:,}\")\n",
    "print(f\"‚è±Ô∏è Tiempo estimado: ~{total_combinations * 2 // 60} minutos\\n\")\n",
    "\n",
    "lgb_grid = GridSearchCV(\n",
    "    lgb.LGBMClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    param_grid=param_grid_lgb,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Iniciando GridSearchCV para LightGBM...\")\n",
    "lgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Optimizaci√≥n completada!\")\n",
    "print(f\"\\nüèÜ Mejores hiperpar√°metros:\")\n",
    "for param, value in lgb_grid.best_params_.items():\n",
    "    print(f\"   - {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä Mejor AUC-ROC (5-fold CV): {lgb_grid.best_score_:.4f}\")\n",
    "\n",
    "best_lgb = lgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar mejor LightGBM en validation\n",
    "y_val_pred_lgb_opt = best_lgb.predict(X_val)\n",
    "y_val_proba_lgb_opt = best_lgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"üìä M√©tricas LightGBM (Optimizado) en Validation:\")\n",
    "print(f\"   - AUC-ROC: {roc_auc_score(y_val, y_val_proba_lgb_opt):.4f}\")\n",
    "print(f\"   - F1-Score: {f1_score(y_val, y_val_pred_lgb_opt):.4f}\")\n",
    "print(f\"   - Precision: {precision_score(y_val, y_val_pred_lgb_opt):.4f}\")\n",
    "print(f\"   - Recall: {recall_score(y_val, y_val_pred_lgb_opt):.4f}\")\n",
    "\n",
    "# Precision@20%\n",
    "top_20_idx_lgb = np.argsort(y_val_proba_lgb_opt)[-int(len(y_val) * 0.20):]\n",
    "precision_at_20_lgb = y_val.iloc[top_20_idx_lgb].mean()\n",
    "print(f\"   - Precision@20%: {precision_at_20_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaci√≥n de Modelos y Selecci√≥n del Mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARACI√ìN DE MODELOS EN VALIDATION SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear tabla comparativa\n",
    "results = pd.DataFrame({\n",
    "    'Random Forest': {\n",
    "        'AUC-ROC': roc_auc_score(y_val, y_val_proba_rf_opt),\n",
    "        'F1-Score': f1_score(y_val, y_val_pred_rf_opt),\n",
    "        'Precision': precision_score(y_val, y_val_pred_rf_opt),\n",
    "        'Recall': recall_score(y_val, y_val_pred_rf_opt),\n",
    "        'Precision@20%': precision_at_20\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'AUC-ROC': roc_auc_score(y_val, y_val_proba_xgb_opt),\n",
    "        'F1-Score': f1_score(y_val, y_val_pred_xgb_opt),\n",
    "        'Precision': precision_score(y_val, y_val_pred_xgb_opt),\n",
    "        'Recall': recall_score(y_val, y_val_pred_xgb_opt),\n",
    "        'Precision@20%': precision_at_20_xgb\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'AUC-ROC': roc_auc_score(y_val, y_val_proba_lgb_opt),\n",
    "        'F1-Score': f1_score(y_val, y_val_pred_lgb_opt),\n",
    "        'Precision': precision_score(y_val, y_val_pred_lgb_opt),\n",
    "        'Recall': recall_score(y_val, y_val_pred_lgb_opt),\n",
    "        'Precision@20%': precision_at_20_lgb\n",
    "    }\n",
    "}).T\n",
    "\n",
    "print(\"\\n\")\n",
    "print(results.to_string())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Identificar mejor modelo por m√©trica\n",
    "print(\"üèÜ Mejor modelo por m√©trica:\")\n",
    "for metric in results.columns:\n",
    "    best_model = results[metric].idxmax()\n",
    "    best_value = results[metric].max()\n",
    "    print(f\"   - {metric}: {best_model} ({best_value:.4f})\")\n",
    "\n",
    "# Seleccionar mejor modelo basado en AUC-ROC (m√©trica principal)\n",
    "best_model_name = results['AUC-ROC'].idxmax()\n",
    "best_auc = results.loc[best_model_name, 'AUC-ROC']\n",
    "\n",
    "print(f\"\\nüéØ MEJOR MODELO SELECCIONADO: {best_model_name}\")\n",
    "print(f\"   - AUC-ROC: {best_auc:.4f} {'‚úÖ (>0.75 objetivo alcanzado)' if best_auc > 0.75 else '‚ö†Ô∏è (< 0.75 objetivo)'}\")\n",
    "\n",
    "# Asignar mejor modelo\n",
    "if best_model_name == 'Random Forest':\n",
    "    best_model = best_rf\n",
    "    y_val_proba_best = y_val_proba_rf_opt\n",
    "    y_val_pred_best = y_val_pred_rf_opt\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model = best_xgb\n",
    "    y_val_proba_best = y_val_proba_xgb_opt\n",
    "    y_val_pred_best = y_val_pred_xgb_opt\n",
    "else:\n",
    "    best_model = best_lgb\n",
    "    y_val_proba_best = y_val_proba_lgb_opt\n",
    "    y_val_pred_best = y_val_pred_lgb_opt\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluaci√≥n Cuantitativa Detallada del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üìä EVALUACI√ìN DETALLADA: {best_model_name}\\n\")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_val, y_val_pred_best)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matriz de confusi√≥n - Counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['No High-Growth', 'High-Growth'],\n",
    "            yticklabels=['No High-Growth', 'High-Growth'])\n",
    "axes[0].set_title(f'Matriz de Confusi√≥n - {best_model_name}\\n(Counts)', fontsize=12)\n",
    "axes[0].set_ylabel('Valor Real')\n",
    "axes[0].set_xlabel('Valor Predicho')\n",
    "\n",
    "# Matriz de confusi√≥n - Normalized\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=['No High-Growth', 'High-Growth'],\n",
    "            yticklabels=['No High-Growth', 'High-Growth'])\n",
    "axes[1].set_title(f'Matriz de Confusi√≥n - {best_model_name}\\n(Normalized)', fontsize=12)\n",
    "axes[1].set_ylabel('Valor Real')\n",
    "axes[1].set_xlabel('Valor Predicho')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../documento/figuras/confusion_matrix_best_model.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Matriz de confusi√≥n guardada en documento/figuras/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas ROC y Precision-Recall\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_val, y_val_proba_best)\n",
    "auc_score = roc_auc_score(y_val, y_val_proba_best)\n",
    "\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title(f'ROC Curve - {best_model_name}')\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_val, y_val_proba_best)\n",
    "ap_score = average_precision_score(y_val, y_val_proba_best)\n",
    "\n",
    "axes[1].plot(recall_curve, precision_curve, color='green', lw=2, label=f'PR curve (AP = {ap_score:.4f})')\n",
    "axes[1].axhline(y=y_val.mean(), color='navy', linestyle='--', lw=2, label=f'Baseline (prevalence = {y_val.mean():.4f})')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title(f'Precision-Recall Curve - {best_model_name}')\n",
    "axes[1].legend(loc=\"lower left\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../documento/figuras/roc_pr_curves_best_model.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Curvas ROC y PR guardadas en documento/figuras/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nüìã Classification Report (Validation):\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_val, y_val_pred_best, target_names=['No High-Growth', 'High-Growth']))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluaci√≥n Cualitativa: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üîç AN√ÅLISIS DE FEATURE IMPORTANCE - {best_model_name}\\n\")\n",
    "\n",
    "# Obtener feature importances\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"üìä Top 20 Features M√°s Importantes:\\n\")\n",
    "    print(feature_importance_df.head(20).to_string(index=False))\n",
    "    \n",
    "    # Visualizar\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    top_20 = feature_importance_df.head(20)\n",
    "    ax.barh(range(len(top_20)), top_20['importance'], color='steelblue')\n",
    "    ax.set_yticks(range(len(top_20)))\n",
    "    ax.set_yticklabels(top_20['feature'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title(f'Top 20 Feature Importances - {best_model_name}', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../documento/figuras/feature_importance_best_model.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Feature importance guardado en documento/figuras/\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è El modelo no soporta feature_importances_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 An√°lisis de Errores (Casos Mal Clasificados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîé AN√ÅLISIS DE ERRORES\\n\")\n",
    "\n",
    "# Identificar errores\n",
    "errors_df = val_df.copy()\n",
    "errors_df['prediction'] = y_val_pred_best\n",
    "errors_df['probability'] = y_val_proba_best\n",
    "errors_df['error'] = (errors_df['high_growth'] != errors_df['prediction']).astype(int)\n",
    "\n",
    "# False Positives (predijo high-growth pero no lo es)\n",
    "false_positives = errors_df[(errors_df['high_growth'] == 0) & (errors_df['prediction'] == 1)]\n",
    "print(f\"üìç False Positives: {len(false_positives):,} ({len(false_positives)/len(errors_df)*100:.2f}%)\")\n",
    "\n",
    "# False Negatives (predijo no high-growth pero s√≠ lo es)\n",
    "false_negatives = errors_df[(errors_df['high_growth'] == 1) & (errors_df['prediction'] == 0)]\n",
    "print(f\"üìç False Negatives: {len(false_negatives):,} ({len(false_negatives)/len(errors_df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nüìä Estad√≠sticas de False Positives (top 5 con mayor probabilidad):\")\n",
    "fp_top = false_positives.nlargest(5, 'probability')[['delta_orders', 'prediction', 'probability']]\n",
    "print(fp_top)\n",
    "\n",
    "print(f\"\\nüìä Estad√≠sticas de False Negatives (top 5 con menor probabilidad):\")\n",
    "fn_top = false_negatives.nsmallest(5, 'probability')[['delta_orders', 'prediction', 'probability']]\n",
    "print(fn_top)\n",
    "\n",
    "print(f\"\\nüí° Insights:\")\n",
    "print(f\"   - FP promedio delta: {false_positives['delta_orders'].mean():.2f} √≥rdenes\")\n",
    "print(f\"   - FN promedio delta: {false_negatives['delta_orders'].mean():.2f} √≥rdenes\")\n",
    "print(f\"   - Los FN son usuarios con alto crecimiento que el modelo subestima\")\n",
    "print(f\"   - Los FP son usuarios que el modelo sobreestima (riesgo menor para negocio)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluaci√≥n Final en Test Set (Una Sola Vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"EVALUACI√ìN FINAL EN TEST SET - {best_model_name}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANTE: Esta evaluaci√≥n se realiza UNA SOLA VEZ en el conjunto de test.\\n\")\n",
    "\n",
    "# Predicciones en test\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# M√©tricas finales\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Precision@20%\n",
    "top_20_idx_test = np.argsort(y_test_proba)[-int(len(y_test) * 0.20):]\n",
    "test_precision_at_20 = y_test.iloc[top_20_idx_test].mean()\n",
    "\n",
    "print(f\"\\nüìä M√âTRICAS FINALES EN TEST SET:\\n\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'M√©trica':<25} {'Valor':>15} {'Objetivo':>15}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'AUC-ROC':<25} {test_auc:>15.4f} {'>0.75':>15} {'‚úÖ' if test_auc > 0.75 else '‚ö†Ô∏è'}\")\n",
    "print(f\"{'F1-Score':<25} {test_f1:>15.4f} {'>0.65':>15} {'‚úÖ' if test_f1 > 0.65 else '‚ö†Ô∏è'}\")\n",
    "print(f\"{'Precision@20%':<25} {test_precision_at_20:>15.4f} {'>0.80':>15} {'‚úÖ' if test_precision_at_20 > 0.80 else '‚ö†Ô∏è'}\")\n",
    "print(f\"{'Precision':<25} {test_precision:>15.4f} {'':>15}\")\n",
    "print(f\"{'Recall':<25} {test_recall:>15.4f} {'':>15}\")\n",
    "print(f\"{'Accuracy':<25} {test_accuracy:>15.4f} {'':>15}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Matriz de confusi√≥n test\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"\\nüìä Matriz de Confusi√≥n (Test):\")\n",
    "print(cm_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluaci√≥n en test set completada\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar Mejor Modelo y Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"üíæ Guardando mejor modelo y reporte...\\n\")\n",
    "\n",
    "# Crear directorio si no existe\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../documento/figuras', exist_ok=True)\n",
    "\n",
    "# Guardar modelo\n",
    "model_path = '../models/best_classifier.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"‚úÖ Modelo guardado: {model_path}\")\n",
    "\n",
    "# Crear reporte\n",
    "report = {\n",
    "    'model_type': best_model_name,\n",
    "    'model_class': str(type(best_model)),\n",
    "    'best_params': best_model.get_params() if hasattr(best_model, 'get_params') else {},\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'dataset_sizes': {\n",
    "        'train': len(X_train),\n",
    "        'validation': len(X_val),\n",
    "        'test': len(X_test)\n",
    "    },\n",
    "    'metrics_validation': {\n",
    "        'auc_roc': float(roc_auc_score(y_val, y_val_proba_best)),\n",
    "        'f1_score': float(f1_score(y_val, y_val_pred_best)),\n",
    "        'precision': float(precision_score(y_val, y_val_pred_best)),\n",
    "        'recall': float(recall_score(y_val, y_val_pred_best)),\n",
    "        'precision_at_20': float(y_val.iloc[top_20_idx].mean())\n",
    "    },\n",
    "    'metrics_test': {\n",
    "        'auc_roc': float(test_auc),\n",
    "        'f1_score': float(test_f1),\n",
    "        'precision': float(test_precision),\n",
    "        'recall': float(test_recall),\n",
    "        'accuracy': float(test_accuracy),\n",
    "        'precision_at_20': float(test_precision_at_20)\n",
    "    },\n",
    "    'feature_count': len(feature_cols),\n",
    "    'feature_names': feature_cols,\n",
    "    'class_distribution_test': {\n",
    "        'negative': int((y_test == 0).sum()),\n",
    "        'positive': int((y_test == 1).sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar reporte como JSON\n",
    "report_path = '../models/classification_report.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Reporte guardado: {report_path}\")\n",
    "\n",
    "# Guardar feature importance si est√° disponible\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance_path = '../models/feature_importance.csv'\n",
    "    feature_importance_df.to_csv(feature_importance_path, index=False)\n",
    "    print(f\"‚úÖ Feature importance guardado: {feature_importance_path}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Todos los artefactos guardados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Resumen Ejecutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RESUMEN EJECUTIVO - ENTRENAMIENTO DE MODELOS DE CLASIFICACI√ìN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüéØ OBJETIVO:\")\n",
    "print(f\"   Predecir usuarios con alto potencial de crecimiento (high_growth)\")\n",
    "\n",
    "print(f\"\\nüìä DATOS:\")\n",
    "print(f\"   - Train: {len(X_train):,} usuarios (60%)\")\n",
    "print(f\"   - Validation: {len(X_val):,} usuarios (20%)\")\n",
    "print(f\"   - Test: {len(X_test):,} usuarios (20%)\")\n",
    "print(f\"   - Features: {len(feature_cols)} (11 num√©ricos + 40 categ√≥ricos)\")\n",
    "print(f\"   - Desbalance: {y_train.mean()*100:.1f}% positivos\")\n",
    "\n",
    "print(f\"\\nü§ñ MODELOS EVALUADOS:\")\n",
    "print(f\"   1. Random Forest Classifier (con GridSearchCV)\")\n",
    "print(f\"   2. XGBoost Classifier (con GridSearchCV)\")\n",
    "print(f\"   3. LightGBM Classifier (con GridSearchCV)\")\n",
    "\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"\\nüìà M√âTRICAS EN TEST SET (evaluaci√≥n final):\")\n",
    "print(f\"   - AUC-ROC: {test_auc:.4f} (objetivo: >0.75) {'‚úÖ' if test_auc > 0.75 else '‚ö†Ô∏è'}\")\n",
    "print(f\"   - F1-Score: {test_f1:.4f} (objetivo: >0.65) {'‚úÖ' if test_f1 > 0.65 else '‚ö†Ô∏è'}\")\n",
    "print(f\"   - Precision@20%: {test_precision_at_20:.4f} (objetivo: >0.80) {'‚úÖ' if test_precision_at_20 > 0.80 else '‚ö†Ô∏è'}\")\n",
    "print(f\"   - Precision: {test_precision:.4f}\")\n",
    "print(f\"   - Recall: {test_recall:.4f}\")\n",
    "print(f\"   - Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nüíº IMPLICACIONES DE NEGOCIO:\")\n",
    "print(f\"   - El modelo puede identificar usuarios high-growth con {test_auc:.1%} de precisi√≥n\")\n",
    "print(f\"   - Al targetear el top-20% de usuarios, {test_precision_at_20:.1%} ser√°n realmente high-growth\")\n",
    "print(f\"   - Esto permite optimizar presupuesto promocional enfoc√°ndose en usuarios de mayor ROI\")\n",
    "\n",
    "print(f\"\\nüìÅ ARTEFACTOS GENERADOS:\")\n",
    "print(f\"   - models/best_classifier.pkl (modelo entrenado)\")\n",
    "print(f\"   - models/classification_report.json (m√©tricas detalladas)\")\n",
    "print(f\"   - models/feature_importance.csv (importancia de features)\")\n",
    "print(f\"   - documento/figuras/confusion_matrix_best_model.png\")\n",
    "print(f\"   - documento/figuras/roc_pr_curves_best_model.png\")\n",
    "print(f\"   - documento/figuras/feature_importance_best_model.png\")\n",
    "\n",
    "print(f\"\\nüöÄ PR√ìXIMO PASO:\")\n",
    "print(f\"   Fase 5: Construcci√≥n del Dashboard con Streamlit\")\n",
    "print(f\"   - Integrar modelo entrenado\")\n",
    "print(f\"   - Crear interfaz para predicciones en tiempo real\")\n",
    "print(f\"   - Sistema de recomendaciones personalizadas\")\n",
    "\n",
    "print(f\"\\n‚úÖ ENTRENAMIENTO DE MODELOS COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
