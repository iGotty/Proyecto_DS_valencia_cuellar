"""
Affinity Analysis Script
=========================
An√°lisis profundo de las afinidades de consumo de usuarios.

Este script analiza las variables tipo diccionario que contienen:
- main_category_counts: Afinidades por categor√≠a de producto
- ka_type_counts: Afinidades por tipo de tienda (KA)
- shop_name_counts: Afinidades por tienda espec√≠fica
- brand_name_counts: Afinidades por marca

Autor: Proyecto Final - Ciencia de Datos Aplicada
Fecha: 2025-10-19
"""

import pandas as pd
import numpy as np
import json
import ast
from collections import Counter, defaultdict
import warnings
warnings.filterwarnings('ignore')


class AffinityAnalyzer:
    """Clase para an√°lisis de afinidades de consumo"""

    def __init__(self, filepath):
        """
        Inicializa el analizador de afinidades

        Parameters:
        -----------
        filepath : str
            Ruta al archivo CSV del dataset
        """
        print("="*80)
        print("AN√ÅLISIS DE AFINIDADES DE CONSUMO")
        print("="*80)
        print(f"\n[INFO] Cargando dataset desde: {filepath}")
        self.df = pd.read_csv(filepath)
        print(f"[OK] Dataset cargado: {self.df.shape[0]:,} filas x {self.df.shape[1]} columnas\n")

        # Convertir las columnas de diccionarios de string a dict
        self._parse_dict_columns()

    def _parse_dict_columns(self):
        """Convierte las columnas que son strings de diccionarios a diccionarios reales"""
        dict_columns = ['main_category_counts', 'ka_type_counts', 'shop_name_counts', 'brand_name_counts']

        print("[INFO] Parseando columnas de diccionarios...")
        for col in dict_columns:
            if col in self.df.columns:
                try:
                    self.df[col] = self.df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)
                    print(f"  ‚úì {col} parseado correctamente")
                except Exception as e:
                    print(f"  ‚úó Error parseando {col}: {str(e)}")

        print("[OK] Parseo completado\n")

    def analyze_category_affinity(self):
        """An√°lisis de afinidad por categor√≠a principal"""
        print("\n" + "="*80)
        print("1. AN√ÅLISIS DE AFINIDAD POR CATEGOR√çA PRINCIPAL")
        print("="*80)

        # Extraer todas las categor√≠as
        all_categories = Counter()
        total_category_orders = 0

        for idx, row in self.df.iterrows():
            categories = row['main_category_counts']
            if isinstance(categories, dict):
                for cat, count in categories.items():
                    all_categories[cat] += count
                    total_category_orders += count

        print(f"\nüìä Resumen General:")
        print(f"   Total de categor√≠as √∫nicas: {len(all_categories)}")
        print(f"   Total de √≥rdenes por categor√≠a: {total_category_orders:,}")

        # Top 20 categor√≠as m√°s populares
        print(f"\nüîù Top 20 Categor√≠as M√°s Populares:")
        top_categories = pd.DataFrame(all_categories.most_common(20), columns=['Categor√≠a', 'Total_√ìrdenes'])
        top_categories['Porcentaje'] = (top_categories['Total_√ìrdenes'] / total_category_orders * 100).round(2)
        top_categories['Porcentaje_Acumulado'] = top_categories['Porcentaje'].cumsum().round(2)
        print(top_categories.to_string(index=False))

        # An√°lisis de diversidad de categor√≠as por usuario
        print(f"\nüìà Diversidad de Categor√≠as por Usuario:")
        category_diversity = self.df['main_category_counts'].apply(lambda x: len(x) if isinstance(x, dict) else 0)
        print(f"   Promedio de categor√≠as por usuario: {category_diversity.mean():.2f}")
        print(f"   Mediana de categor√≠as por usuario: {category_diversity.median():.0f}")
        print(f"   Rango: [{category_diversity.min()}, {category_diversity.max()}]")

        print(f"\n   Distribuci√≥n de diversidad:")
        diversity_dist = category_diversity.value_counts().sort_index()
        for n_cats, n_users in diversity_dist.head(10).items():
            pct = (n_users / len(self.df) * 100)
            print(f"     {n_cats} categor√≠as: {n_users:,} usuarios ({pct:.1f}%)")

        # Concentraci√≥n: ¬øCu√°ntas categor√≠as representan el 80% de las √≥rdenes?
        cumsum_80 = top_categories[top_categories['Porcentaje_Acumulado'] <= 80]
        print(f"\nüí° Insight de Concentraci√≥n:")
        print(f"   {len(cumsum_80)} categor√≠as representan el 80% de todas las √≥rdenes")

        return {
            'all_categories': all_categories,
            'top_categories': top_categories,
            'diversity': category_diversity
        }

    def analyze_ka_type_affinity(self):
        """An√°lisis de afinidad por tipo de tienda (KA Type)"""
        print("\n" + "="*80)
        print("2. AN√ÅLISIS DE AFINIDAD POR TIPO DE TIENDA (KA TYPE)")
        print("="*80)

        # Extraer todos los tipos de KA
        all_ka_types = Counter()
        total_ka_orders = 0

        for idx, row in self.df.iterrows():
            ka_types = row['ka_type_counts']
            if isinstance(ka_types, dict):
                for ka, count in ka_types.items():
                    all_ka_types[ka] += count
                    total_ka_orders += count

        print(f"\nüìä Resumen General:")
        print(f"   Total de tipos de KA √∫nicos: {len(all_ka_types)}")
        print(f"   Total de √≥rdenes por tipo de KA: {total_ka_orders:,}")

        # Distribuci√≥n de tipos de KA
        print(f"\nüè™ Distribuci√≥n de Tipos de Tienda:")
        ka_df = pd.DataFrame(all_ka_types.most_common(), columns=['Tipo_KA', 'Total_√ìrdenes'])
        ka_df['Porcentaje'] = (ka_df['Total_√ìrdenes'] / total_ka_orders * 100).round(2)
        print(ka_df.to_string(index=False))

        # An√°lisis de diversidad de KA types por usuario
        print(f"\nüìà Diversidad de Tipos de Tienda por Usuario:")
        ka_diversity = self.df['ka_type_counts'].apply(lambda x: len(x) if isinstance(x, dict) else 0)
        print(f"   Promedio de tipos de KA por usuario: {ka_diversity.mean():.2f}")
        print(f"   Mediana de tipos de KA por usuario: {ka_diversity.median():.0f}")

        print(f"\n   Distribuci√≥n de diversidad:")
        ka_diversity_dist = ka_diversity.value_counts().sort_index()
        for n_types, n_users in ka_diversity_dist.items():
            pct = (n_users / len(self.df) * 100)
            print(f"     {n_types} tipos de KA: {n_users:,} usuarios ({pct:.1f}%)")

        return {
            'all_ka_types': all_ka_types,
            'ka_df': ka_df,
            'diversity': ka_diversity
        }

    def analyze_shop_affinity(self):
        """An√°lisis de afinidad por tienda espec√≠fica"""
        print("\n" + "="*80)
        print("3. AN√ÅLISIS DE AFINIDAD POR TIENDA ESPEC√çFICA")
        print("="*80)

        # Extraer todas las tiendas
        all_shops = Counter()
        total_shop_orders = 0

        for idx, row in self.df.iterrows():
            shops = row['shop_name_counts']
            if isinstance(shops, dict):
                for shop, count in shops.items():
                    all_shops[shop] += count
                    total_shop_orders += count

        print(f"\nüìä Resumen General:")
        print(f"   Total de tiendas √∫nicas: {len(all_shops)}")
        print(f"   Total de √≥rdenes por tienda: {total_shop_orders:,}")

        # Top 20 tiendas m√°s populares
        print(f"\nüîù Top 20 Tiendas M√°s Populares:")
        top_shops = pd.DataFrame(all_shops.most_common(20), columns=['Tienda', 'Total_√ìrdenes'])
        top_shops['Porcentaje'] = (top_shops['Total_√ìrdenes'] / total_shop_orders * 100).round(2)
        top_shops['Porcentaje_Acumulado'] = top_shops['Porcentaje'].cumsum().round(2)
        print(top_shops.to_string(index=False))

        # An√°lisis de lealtad a tiendas
        print(f"\nüéØ An√°lisis de Lealtad a Tiendas:")
        shop_diversity = self.df['shop_name_counts'].apply(lambda x: len(x) if isinstance(x, dict) else 0)
        print(f"   Promedio de tiendas visitadas por usuario: {shop_diversity.mean():.2f}")
        print(f"   Mediana de tiendas visitadas por usuario: {shop_diversity.median():.0f}")

        # Usuarios que compran en una sola tienda vs. m√∫ltiples
        single_shop_users = (shop_diversity == 1).sum()
        multi_shop_users = (shop_diversity > 1).sum()
        print(f"\n   üë§ Usuarios con 1 sola tienda: {single_shop_users:,} ({single_shop_users/len(self.df)*100:.1f}%)")
        print(f"   üë• Usuarios con m√∫ltiples tiendas: {multi_shop_users:,} ({multi_shop_users/len(self.df)*100:.1f}%)")

        # Concentraci√≥n
        cumsum_80 = top_shops[top_shops['Porcentaje_Acumulado'] <= 80]
        print(f"\nüí° Insight de Concentraci√≥n:")
        print(f"   {len(cumsum_80)} tiendas representan el 80% de todas las √≥rdenes")

        return {
            'all_shops': all_shops,
            'top_shops': top_shops,
            'diversity': shop_diversity
        }

    def analyze_brand_affinity(self):
        """An√°lisis de afinidad por marca"""
        print("\n" + "="*80)
        print("4. AN√ÅLISIS DE AFINIDAD POR MARCA")
        print("="*80)

        # Extraer todas las marcas
        all_brands = Counter()
        total_brand_orders = 0

        for idx, row in self.df.iterrows():
            brands = row['brand_name_counts']
            if isinstance(brands, dict):
                for brand, count in brands.items():
                    all_brands[brand] += count
                    total_brand_orders += count

        print(f"\nüìä Resumen General:")
        print(f"   Total de marcas √∫nicas: {len(all_brands)}")
        print(f"   Total de √≥rdenes por marca: {total_brand_orders:,}")

        # Top 20 marcas m√°s populares
        print(f"\nüîù Top 20 Marcas M√°s Populares:")
        top_brands = pd.DataFrame(all_brands.most_common(20), columns=['Marca', 'Total_√ìrdenes'])
        top_brands['Porcentaje'] = (top_brands['Total_√ìrdenes'] / total_brand_orders * 100).round(2)
        top_brands['Porcentaje_Acumulado'] = top_brands['Porcentaje'].cumsum().round(2)
        print(top_brands.to_string(index=False))

        # An√°lisis de lealtad a marcas
        print(f"\nüéØ An√°lisis de Lealtad a Marcas:")
        brand_diversity = self.df['brand_name_counts'].apply(lambda x: len(x) if isinstance(x, dict) else 0)
        print(f"   Promedio de marcas compradas por usuario: {brand_diversity.mean():.2f}")
        print(f"   Mediana de marcas compradas por usuario: {brand_diversity.median():.0f}")

        # Concentraci√≥n
        cumsum_80 = top_brands[top_brands['Porcentaje_Acumulado'] <= 80]
        print(f"\nüí° Insight de Concentraci√≥n:")
        print(f"   {len(cumsum_80)} marcas representan el 80% de todas las √≥rdenes")

        return {
            'all_brands': all_brands,
            'top_brands': top_brands,
            'diversity': brand_diversity
        }

    def analyze_cross_affinity(self):
        """An√°lisis cruzado de afinidades"""
        print("\n" + "="*80)
        print("5. AN√ÅLISIS CRUZADO DE AFINIDADES")
        print("="*80)

        # Crear una categor√≠a dominante para cada usuario
        print("\nüìä Categor√≠a Dominante por Usuario:")
        self.df['dominant_category'] = self.df['main_category_counts'].apply(
            lambda x: max(x.items(), key=lambda i: i[1])[0] if isinstance(x, dict) and len(x) > 0 else None
        )

        dominant_cat_dist = self.df['dominant_category'].value_counts().head(10)
        print("\n  Top 10 categor√≠as dominantes:")
        for cat, count in dominant_cat_dist.items():
            pct = (count / len(self.df) * 100)
            print(f"    {cat}: {count:,} usuarios ({pct:.1f}%)")

        # Tipo de KA dominante
        print("\n\nüè™ Tipo de Tienda Dominante por Usuario:")
        self.df['dominant_ka_type'] = self.df['ka_type_counts'].apply(
            lambda x: max(x.items(), key=lambda i: i[1])[0] if isinstance(x, dict) and len(x) > 0 else None
        )

        dominant_ka_dist = self.df['dominant_ka_type'].value_counts()
        print("\n  Distribuci√≥n de tipos de tienda dominantes:")
        for ka, count in dominant_ka_dist.items():
            pct = (count / len(self.df) * 100)
            print(f"    {ka}: {count:,} usuarios ({pct:.1f}%)")

        # An√°lisis de especializaci√≥n vs diversificaci√≥n
        print("\n\nüéØ √çndice de Especializaci√≥n vs. Diversificaci√≥n:")

        # Calcular √≠ndice de concentraci√≥n (Herfindahl) para categor√≠as
        def herfindahl_index(counts_dict):
            """Calcula el √≠ndice de Herfindahl-Hirschman (concentraci√≥n)"""
            if not isinstance(counts_dict, dict) or len(counts_dict) == 0:
                return 0
            total = sum(counts_dict.values())
            if total == 0:
                return 0
            return sum((count / total) ** 2 for count in counts_dict.values())

        self.df['category_concentration'] = self.df['main_category_counts'].apply(herfindahl_index)

        print(f"   Concentraci√≥n en categor√≠as (√≠ndice Herfindahl):")
        print(f"     Promedio: {self.df['category_concentration'].mean():.3f}")
        print(f"     Mediana: {self.df['category_concentration'].median():.3f}")
        print(f"\n   Interpretaci√≥n:")
        print(f"     - Cercano a 1.0 = Usuario muy especializado (compra en pocas categor√≠as)")
        print(f"     - Cercano a 0.0 = Usuario muy diversificado (compra en muchas categor√≠as)")

        # Segmentar usuarios por concentraci√≥n
        self.df['user_type'] = pd.cut(
            self.df['category_concentration'],
            bins=[0, 0.33, 0.66, 1.0],
            labels=['Diversificado', 'Moderado', 'Especializado']
        )

        print(f"\n   Segmentaci√≥n de usuarios:")
        user_type_dist = self.df['user_type'].value_counts()
        for utype, count in user_type_dist.items():
            pct = (count / len(self.df) * 100)
            print(f"     {utype}: {count:,} usuarios ({pct:.1f}%)")

        return {
            'dominant_cat_dist': dominant_cat_dist,
            'dominant_ka_dist': dominant_ka_dist,
            'user_type_dist': user_type_dist
        }

    def generate_affinity_summary(self):
        """Genera un resumen ejecutivo de afinidades"""
        print("\n" + "="*80)
        print("RESUMEN EJECUTIVO - AFINIDADES DE CONSUMO")
        print("="*80)

        # Calcular m√©tricas clave
        category_diversity = self.df['main_category_counts'].apply(lambda x: len(x) if isinstance(x, dict) else 0)
        shop_diversity = self.df['shop_name_counts'].apply(lambda x: len(x) if isinstance(x, dict) else 0)
        brand_diversity = self.df['brand_name_counts'].apply(lambda x: len(x) if isinstance(x, dict) else 0)
        ka_diversity = self.df['ka_type_counts'].apply(lambda x: len(x) if isinstance(x, dict) else 0)

        print(f"""
üéØ Diversidad Promedio por Usuario:
   - Categor√≠as: {category_diversity.mean():.2f}
   - Tipos de tienda: {ka_diversity.mean():.2f}
   - Tiendas espec√≠ficas: {shop_diversity.mean():.2f}
   - Marcas: {brand_diversity.mean():.2f}

üí° Insights Clave:
   1. Los usuarios tienen un comportamiento {'diversificado' if category_diversity.mean() > 3 else 'concentrado'} en categor√≠as
   2. El promedio de tiendas visitadas ({shop_diversity.mean():.1f}) sugiere {'alta exploraci√≥n' if shop_diversity.mean() > 5 else 'lealtad a pocas tiendas'}
   3. La base de usuarios es {'heterog√©nea' if len(self.df['dominant_category'].unique()) > 10 else 'homog√©nea'} en sus preferencias

üé≤ Concentraci√≥n del Mercado:
   - √çndice de concentraci√≥n promedio: {self.df['category_concentration'].mean():.3f}
   - Usuarios especializados: {(self.df['user_type'] == 'Especializado').sum()} ({(self.df['user_type'] == 'Especializado').sum()/len(self.df)*100:.1f}%)
   - Usuarios diversificados: {(self.df['user_type'] == 'Diversificado').sum()} ({(self.df['user_type'] == 'Diversificado').sum()/len(self.df)*100:.1f}%)
""")

    def run_full_analysis(self):
        """Ejecuta el an√°lisis completo de afinidades"""
        print("\n")
        print("üöÄ Iniciando an√°lisis completo de afinidades...\n")

        # Ejecutar todos los an√°lisis
        category_results = self.analyze_category_affinity()
        ka_results = self.analyze_ka_type_affinity()
        shop_results = self.analyze_shop_affinity()
        brand_results = self.analyze_brand_affinity()
        cross_results = self.analyze_cross_affinity()
        self.generate_affinity_summary()

        print("\n" + "="*80)
        print("‚úÖ An√°lisis de afinidades completado")
        print("="*80)

        return {
            'category_results': category_results,
            'ka_results': ka_results,
            'shop_results': shop_results,
            'brand_results': brand_results,
            'cross_results': cross_results,
            'df_enriched': self.df
        }


if __name__ == "__main__":
    # Ruta al dataset
    DATASET_PATH = "../dataset_protegido (1).csv"

    # Crear instancia del analizador
    analyzer = AffinityAnalyzer(DATASET_PATH)

    # Ejecutar an√°lisis completo
    results = analyzer.run_full_analysis()

    print("\nüí° Pr√≥ximos pasos recomendados:")
    print("   1. Usar las categor√≠as/marcas/tiendas dominantes para segmentaci√≥n")
    print("   2. Analizar relaci√≥n entre especializaci√≥n y crecimiento de √≥rdenes")
    print("   3. Identificar oportunidades de cross-selling basadas en afinidades")
